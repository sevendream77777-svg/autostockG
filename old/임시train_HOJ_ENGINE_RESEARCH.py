# ===========================================================
# train_HOJ_ENGINE_RESEARCH.py
# ì—°êµ¬ìš© HOJ ì—”ì§„ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (HOJ_DB_RESEARCH_V31 ê¸°ì¤€)
# ===========================================================

import os
import pickle
from datetime import timedelta

import numpy as np
import pandas as pd
import lightgbm as lgb

from config_paths import get_path
from version_utils import backup_existing_file


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ë¡œ ì„¤ì • (MODELENGINE êµ¬ì¡° ê¸°ì¤€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH = get_path("HOJ_DB", "RESEARCH", "HOJ_DB_RESEARCH_V31.parquet")
ENGINE_FILE = get_path("HOJ_ENGINE", "RESEARCH", "HOJ_ENGINE_RESEARCH_V31.pkl")

# HOJ ì—”ì§„ í”¼ì²˜ í›„ë³´ (ì—†ëŠ” ì»¬ëŸ¼ì€ ìë™ ì œì™¸)
FEATURE_CANDIDATES = [
    "SMA_20", "SMA_40", "SMA_60", "SMA_90",
    "RSI_14",
    "VOL_SMA_20",
    "MACD", "MACD_Sig",
    "BBP_20",
    "ATR_14",
    "STOCH_K", "STOCH_D",
    "CCI_20",
    "KOSPI_ìˆ˜ìµë¥ ",
    "ALPHA_SMA_20",
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def select_features(df: pd.DataFrame):
    """ë°ì´í„°í”„ë ˆì„ì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒ"""
    available = [f for f in FEATURE_CANDIDATES if f in df.columns]
    missing = [f for f in FEATURE_CANDIDATES if f not in df.columns]

    print(f"  ğŸ” ì‚¬ìš© í”¼ì²˜({len(available)}ê°œ): {', '.join(available) if available else '(ì—†ìŒ)'}")
    if missing:
        print(f"  âš  ëˆ„ë½ëœ í”¼ì²˜({len(missing)}ê°œ): {', '.join(missing)}")

    return available


def train_valid_split_by_date(df: pd.DataFrame, valid_days: int = 365):
    """ë§ˆì§€ë§‰ valid_days ì¼ìë¥¼ ê²€ì¦ ì„¸íŠ¸ë¡œ ì‚¬ìš©í•˜ëŠ” ë¶„ë¦¬ ë°©ì‹"""
    max_date = pd.to_datetime(df["Date"]).max()
    split_date = max_date - timedelta(days=valid_days)

    train_df = df[df["Date"] < split_date]
    valid_df = df[df["Date"] >= split_date]

    return train_df, valid_df, split_date, max_date


def train_regressor(X_train, y_train, X_valid, y_valid):
    """íšŒê·€ ëª¨ë¸ í•™ìŠµ (Return_5d íšŒê·€)"""
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)

    params = {
        "objective": "regression",
        "metric": "rmse",
        "learning_rate": 0.05,
        "num_leaves": 63,
        "feature_fraction": 0.9,
        "bagging_fraction": 0.9,
        "bagging_freq": 1,
        "min_data_in_leaf": 50,
        "verbosity": -1,
    }

    model = lgb.train(
        params,
        train_data,
        num_boost_round=2000,
        valid_sets=[train_data, valid_data],
        valid_names=["train", "valid"],
        early_stopping_rounds=100,
        verbose_eval=100,
    )

    pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)
    rmse = float(np.sqrt(np.mean((y_valid - pred_valid) ** 2)))
    return model, rmse


def train_classifier(X_train, y_train, X_valid, y_valid):
    """ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (Label_5d ìƒìŠ¹/í•˜ë½ êµ¬ë¶„)"""
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)

    params = {
        "objective": "binary",
        "metric": "binary_logloss",
        "learning_rate": 0.05,
        "num_leaves": 63,
        "feature_fraction": 0.9,
        "bagging_fraction": 0.9,
        "bagging_freq": 1,
        "min_data_in_leaf": 50,
        "verbosity": -1,
    }

    model = lgb.train(
        params,
        train_data,
        num_boost_round=2000,
        valid_sets=[train_data, valid_data],
        valid_names=["train", "valid"],
        early_stopping_rounds=100,
        verbose_eval=100,
    )

    prob_valid = model.predict(X_valid, num_iteration=model.best_iteration)
    pred_valid = (prob_valid > 0.5).astype(int)
    acc = float((pred_valid == y_valid).mean())
    return model, acc


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_research_engine():
    print("=== [RESEARCH] HOJ ì—”ì§„ í•™ìŠµ ì‹œì‘ ===")
    print(f"  ğŸ“¥ ì…ë ¥ DB: {DB_PATH}")

    if not os.path.exists(DB_PATH):
        print("âŒ ì—°êµ¬ìš© DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (build_HOJ_DB_RESEARCH.py ë¨¼ì € ì‹¤í–‰ í•„ìš”)")
        return

    df = pd.read_parquet(DB_PATH)
    print(f"  - DB ë¡œë“œ ì™„ë£Œ: {df.shape}")

    # ë‚ ì§œ íƒ€ì… ë³´ì • (ì»¬ëŸ¼ëª…: Date)
    df["Date"] = pd.to_datetime(df["Date"])

    # í”¼ì²˜ ì„ íƒ
    feature_cols = select_features(df)

    # í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼ ì²´í¬
    required_cols = ["Return_5d", "Label_5d"]
    for c in required_cols:
        if c not in df.columns:
            raise KeyError(f"âŒ '{c}' ì»¬ëŸ¼ì´ HOJ_DB_RESEARCH_V31ì— ì—†ìŠµë‹ˆë‹¤.")

    # ê²°ì¸¡ ì œê±°
    df_model = df.dropna(subset=feature_cols + required_cols).reset_index(drop=True)
    print(f"  - ê²°ì¸¡ ì œê±° í›„: {df_model.shape}")

    # Train / Valid ë¶„ë¦¬
    train_df, valid_df, split_date, max_date = train_valid_split_by_date(df_model, valid_days=365)

    print(f"  ğŸ“… í•™ìŠµ ê¸°ê°„: {train_df['Date'].min().date()} ~ {train_df['Date'].max().date()}")
    print(f"  ğŸ“… ê²€ì¦ ê¸°ê°„: {valid_df['Date'].min().date()} ~ {valid_df['Date'].max().date()}")

    X_train = train_df[feature_cols].values
    y_train_reg = train_df["Return_5d"].values
    y_train_cls = train_df["Label_5d"].values

    X_valid = valid_df[feature_cols].values
    y_valid_reg = valid_df["Return_5d"].values
    y_valid_cls = valid_df["Label_5d"].values

    # íšŒê·€ ëª¨ë¸ í•™ìŠµ
    print("\n[1] íšŒê·€ ëª¨ë¸ í•™ìŠµ (Return_5d)")
    reg_model, rmse = train_regressor(X_train, y_train_reg, X_valid, y_valid_reg)
    print(f"   ğŸ“‰ ê²€ì¦ RMSE: {rmse:.6f}")

    # ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
    print("\n[2] ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (Label_5d)")
    cls_model, acc = train_classifier(X_train, y_train_cls, X_valid, y_valid_cls)
    print(f"   ğŸ¯ ê²€ì¦ ì •í™•ë„: {acc:.4f}")

    # ë©”íƒ€ ì •ë³´
    meta = {
        "type": "RESEARCH",
        "features": feature_cols,
        "train_start": str(train_df["Date"].min().date()),
        "train_end": str(train_df["Date"].max().date()),
        "valid_start": str(valid_df["Date"].min().date()),
        "valid_end": str(valid_df["Date"].max().date()),
        "rmse_valid": rmse,
        "acc_valid": acc,
    }

    # ì—”ì§„ ë²ˆë“¤
    engine_bundle = {
        "reg": reg_model,
        "cls": cls_model,
        "features": feature_cols,
        "meta": meta,
    }

    # ê¸°ì¡´ íŒŒì¼ ë°±ì—… + ì €ì¥
    os.makedirs(os.path.dirname(ENGINE_FILE), exist_ok=True)
    backup_existing_file(ENGINE_FILE)

    with open(ENGINE_FILE, "wb") as f:
        pickle.dump(engine_bundle, f)

    print(f"\nğŸ’¾ ì—°êµ¬ìš© ì—”ì§„ ì €ì¥ ì™„ë£Œ â†’ {ENGINE_FILE}")
    print("=== [RESEARCH] HOJ ì—”ì§„ í•™ìŠµ ì¢…ë£Œ ===")


if __name__ == "__main__":
    train_research_engine()

