프로그램 방향

초단타 1시간단위(데이터상 불가)
단타 1일
중타 1주일 내외
장기 1달 이상
각 공식별 프로그램 세팅

추가문제
새로운 데이터가 들어오고
적용이 된다

매일 2800개 데이터 학습? or 업데이트?


9년 기간먼저 학습 후
최근1년데이터로 검증 과정

그 과정에서 공식 수정 및 확률 찾기


데이트 업데이트 동시에 학습과정 진행 및 수정

네, 20일의 대기 시간은 이 프로젝트의 성패를 가르는 \*\*'골든 타임'\*\*입니다. 이 기간 동안 모델을 완벽하게 준비하고, API 연결 후 즉시 실전에 투입할 수 있도록 명확한 로드맵을 정리해 드리겠습니다.

-----

## 1\. 🗓️ 20일간의 과제 (API 대기 기간)

**목표: '최강의 AI 모델'과 '최적의 매도 전략'을 확정하고, UI를 완성합니다.**

### 1\. (V9) '최적 매도 전략' 확정 (방금 완료)

  * **과제:** `run_strategy_grid_search_V9.py` 실행 완료.
  * **결과:** "5일 단순 보유"(V5\_Baseline) 전략이 +3.627%로, 익절/손절을 개입시킨 V6, V7, V8 전략보다 **수익성이 압도적으로 높다**는 충격적인 결론을 얻었습니다.
  * **확정:** 우리의 \*\*'최강 매도 전략'\*\*은 \*\*"AI 추천 Top 1%를 매수 후 5일간 보유(V5\_Baseline)"\*\*입니다.

### 2\. (V10) '최강 AI 모델' 찾기 (사용자님 제안)

  * **과제:** "60일/5일" 모델 외에, **"90일/5일", "60일/10일"** 등 다른 AI 모델 가설을 테스트하여 `+3.627%`의 수익률을 넘어서는 '진짜 챔피언 모델'을 찾습니다.
  * **실행:** `run_strategy_grid_search_V9.py` 스크립트를 **개조**하여, `LOOKBACK_LONGEST` (입력 기간)와 `TARGET_DAYS` (예측 기간)를 바꿔가며 '모델 가설 그리드 서치'를 실행합니다.

### 3\. (V11) UI 프로그램 완성 (실전 준비)

  * **과제:** 현재의 `run_ai_program_v1.py` (PySide6)를 **업그레이드**합니다.
  * **실행:**
    1.  '추천 받기' 버튼을 누르면, **`all_features_cumulative.parquet`** 파일을 1초 만에 로드하여 Top 10을 출력하도록 \*\*'최적화 로직'\*\*을 UI에 이식합니다.
    2.  `update_features_incrementally.py` (8분 걸리는) 스크립트를 실행하는 **'데이터베이스 업데이트' 버튼**을 UI에 추가합니다.

-----

## 2\. 🚀 API 연결 후 과제 (20일 후)

**목표: 한국투자증권 API를 연동하여, 64비트 환경에서 V5 모델을 '실전'에 투입하고 'PBR/PER/수급' V12 필터를 구현합니다.**

### 1\. (필수) 64비트 환경 최종 점검

  * **과제:** 64비트 Python 3.13 환경에서, 32비트에서는 설치가 불가능했던 **모든 라이브러리**가 설치되었는지 최종 확인합니다.
  * **실행:** (이미 완료하셨습니다.)
    ```bash
    pip install pandas lightgbm scikit-learn joblib pykrx tqdm fastparquet pandas-ta numpy scipy
    ```

### 2\. (V12) 'PBR/PER/수급' 필터 최종 구현

  * **과제:** `pykrx`로는 불가능했던 **V10 필터**를, 20일 뒤 **한국투자증권 API**를 통해 '실시간'으로 구현합니다.
  * **실행:**
    1.  AI(V5)가 1차로 'Top 10'을 추천합니다.
    2.  한국투자증권 API가 이 10개 종목의 PBR, PER, 외국인/기관 순매수 데이터를 **실시간 조회**합니다.
    3.  "PBR/PER가 낮고 수급이 좋은" **'최종 3\~5개'** 종목만 선별하여 매수합니다.

### 3\. (V13) '자동매매' 로직 실전 탑재 (최종)

  * **과제:** 1단계(V9)에서 확정된 \*\*'최강 매도 전략' (5일 단순 보유)\*\*을 자동매매 스크립트에 탑재합니다.
  * **실행:**
    1.  **[매수]** 매일 아침 8시 50분, V12 필터를 통과한 '최종 3\~5개' 종목을 **자동 매수**합니다.
    2.  **[매도]** `my_portfolio.csv`에 기록된 종목 중, **매수 후 5일이 경과한** 종목을 **자동 매도**합니다.
    3.  (V9의 결과가 뒤집힐 경우, V6(+7%/-3%) 로직을 대신 탑재합니다.)
---------------------------------------------------------------------


저희의 목표는 8일이 걸릴 700만 건의 전체 데이터가 아닌, **AI가 학습할 가치가 있는 '핵심 샘플'(예: 2만 건)**만 골라내어, **이 2만 건에 대해서만 10년 치 PBR/PER/수급 데이터를 수집(약 33분 소요)**하는 것입니다.

1단계: (V11-A) '핵심 샘플' 리스트 추출 (약 10~15분)
목표: 10년 치 전체 시세(all_stocks_cumulative.parquet)를 스캔하여, "5일 만에 15% 급등" 또는 "5일 만에 10% 급락"한 **'사건(Event)'**이 발생한 날짜와 종목코드 목록(v11_sample_list.parquet)을 추출합니다.

실행: extract_V11_samples.py 스크립트를 실행합니다. (이 코드는 제가 직전에 드렸습니다.)

2단계: (V11-B) 'V11 최종 데이터베이스' 구축 (약 33분 + 8분)
목표: 10년 치 데이터에 16개 피처를 모두 계산한 뒤, 1단계에서 추출한 '핵심 샘플'만 남겨 'V11 최종 DB'를 만듭니다.

실행: build_database_V11.py (새 스크립트)를 실행합니다.

[8분 소요] 10년 치 시세(OHLCV) + KOSPI 데이터를 로드하여, 12개의 V5 기술적 피처(SMA, RSI...)를 먼저 계산합니다. (all_features_cumulative_V12.parquet 생성)

이 12개 피처가 완성된 DB에서, 1단계의 '핵심 샘플' 목록(v11_sample_list.parquet)과 일치하는 데이터만 필터링합니다. (예: 2만 건)

[33분 소요] 이 2만 건의 샘플에 대해서만 pykrx의 올바른 함수(KOSPI/KOSDAQ 분리)를 호출하여 PBR/PER/수급 데이터를 수집합니다.

12개 피처 + 4개 V12 피처 = 16개 피처가 모두 포함된 V11_Database_Final.parquet 파일을 저장합니다.

3단계: (V11-C) 'V11 챔피언 모델' 학습 및 검증 (약 3분)
목표: 'V11 최종 DB'(핵심 샘플)로 학습한 새 AI 모델이, 기존 V5 모델(전체 데이터)의 수익률(+3.627%)을 뛰어넘는지 검증합니다.

실행: run_model_grid_search_V12.py (V11) 스크립트를 개조하여, V11 DB로 **'V11 챔피언 모델'**을 학습하고 백테스팅을 실행합니다.

-----------------------------------------------------
파일 분류,파일명 (예시),용도 및 역할 (프로젝트 핵심)
A. 초기 원천 데이터,collect_all_1y.py,최초 10년치 일봉 데이터(OHLCV)를 수집하는 데 사용된 스크립트.
,all_stocks_cumulative.parquet,10년치 전체 OHLCV 시세 데이터베이스 (누적 데이터). 모든 분석의 출발점.
,collect_kospi.py,KOSPI 지수 데이터를 수집하는 데 사용된 스크립트.
,kospi_index_10y.parquet,10년치 KOSPI 지수 데이터베이스. (ALPHA 계산용)
---,---,---
B. V5 피처 계산,combine_data.py,개별 CSV 파일을 하나의 stock_data_10y_combined.parquet로 통합하는 데 사용됨.
,process_data.py (V4),"OHLCV 데이터에 SMA, RSI 등 12가지 V5 피처를 계산하고 .parquet 파일로 저장하는 데 사용됨."
,all_features_cumulative.parquet,최종 V5 피처 데이터베이스 (12개 지표). (현재 챔피언 모델이 사용하는 DB)
---,---,---
C. 모델 학습 및 검증,create_target_and_split.py,"**'정답(Target_Return)'**을 생성하고, 전체 데이터를 **train_data.parquet / test_data.parquet**로 분리하는 데 사용됨."
,train_champion_reg.py,"**회귀 모델(수익률 예측)**을 학습시키고, 모델 파일을 저장하는 데 사용됨."
,champion_model_60_5.pkl,최종 확정된 챔피언 AI 모델(60일/5일 예측). (AI의 뇌 파일)
,run_regression_60_5.py,챔피언 모델의 하락장/상승장 수익률을 최종 검증하는 데 사용된 스크립트.
---,---,---
D. 실전/최적화 (GUI 및 필터),daily_recommender.py,(최종 실행 파일). AI 모델을 로드하여 '오늘의 Top 10'을 추천하는 데 사용됨. (현재 버전은 V13 코드가 덮여쓰여 있어야 함)
,run_model_grid_search_V12.py,V12/V11 (16개 피처) 모델이 수익률을 더 높이는지 테스트하려 했던 복잡한 그리드 서치 스크립트 (PBR/PER 문제로 현재는 실패함).
,run_event_backtest.py,익절(+7%)/손절(-3%) 로직의 수익률을 검증하는 데 사용된 스크립트.
,run_ai_program_v1.py,PySide6 UI를 띄우고 AI 추천 로직을 버튼에 연결하는 UI 프로그램의 뼈대.
,targets.csv,V11/V12 단계에서 PBR/PER 데이터를 비동기 크롤링하기 위해 생성했던 51만 개 URL 목록.
,naver_crawler_aio.py,51만 개 URL을 병렬로 수집하려 했던 비동기 크롤러 (현재 실패 상태).


수급 투자 주체별 순매수/순매도 금액 또는 수량'