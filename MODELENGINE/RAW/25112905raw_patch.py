# raw_patch.py  (V6 - Kiwoom 1st Source Added)
# ìˆ˜ì •ì‚¬í•­:
# 1. build_daily_from_pykrx ë“± ëˆ„ë½ëœ í•¨ìˆ˜ ë³µêµ¬
# 2. ì´ë¯¸ ìµœì‹  ë°ì´í„°(target_date == last_date)ê°€ ìˆìœ¼ë©´ ìˆ˜ì§‘ SKIP ê¸°ëŠ¥ ì¶”ê°€
# 3. íŒŒì¼ ì €ì¥ ì‹œ ë‚ ì§œ íƒœê·¸ ê·œì¹™ ì¤€ìˆ˜

import os
import sys
import time
import math
import datetime as dt
from functools import lru_cache
from typing import Optional, Tuple, List, Iterable, Callable

import pandas as pd
from pykrx import stock
import requests
import FinanceDataReader as fdr
import glob
import os as _os
import yfinance as yf
import os.path as _path

# ============================================================
#  KIWOOM REST API ê²½ë¡œ/ëª¨ë“ˆ ì„¤ì •
# ============================================================
KIWOOM_REST_DIR = r"F:\autostockG"
if KIWOOM_REST_DIR not in sys.path:
    sys.path.append(KIWOOM_REST_DIR)

# REST API ì „ìš© ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
try:
    from kiwoom_rest.token_manager import KiwoomTokenManager
    from kiwoom_rest.kiwoom_api import KiwoomRestApi
except ImportError:
    print("Warning: kiwoom_rest ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ======================
# ê²½ë¡œ ì„¤ì •
# ======================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
STOCKS_DIR = os.path.join(BASE_DIR, "stocks")
RAW_MAIN = os.path.join(STOCKS_DIR, "all_stocks_cumulative.parquet")
DAILY_DIR = os.path.join(STOCKS_DIR, "DAILY")
LOG_DIR = os.path.join(STOCKS_DIR, "LOGS")
OHLCV_COLS = ["Open", "High", "Low", "Close", "Volume"]

os.makedirs(DAILY_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

# MODELENGINE ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ UTIL ëª¨ë“ˆ ì‚¬ìš©
PROJECT_ROOT = os.path.abspath(os.path.join(BASE_DIR, ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from UTIL.config_paths import versioned_filename
from UTIL.version_utils import save_dataframe_with_date, find_latest_file

def print_header():
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ ğŸ‰ í°ë‘¥ì´ ì›ë³¸ë°ì´í„° ì—…ë°ì´íŠ¸ (V6)           â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print(f"[PATH] RAW_MAIN : {RAW_MAIN}")
    print()

def log(msg: str):
    ts = dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] {msg}")

def _invalid_ohlcv_mask(df: pd.DataFrame) -> pd.Series:
    subset = df[OHLCV_COLS] if all(col in df.columns for col in df.columns) else df
    return subset.isna().any(axis=1) | (subset <= 0).any(axis=1)

# ======================
# ë‚ ì§œ ìœ í‹¸
# ======================
def to_ymd(d: dt.date) -> str:
    return d.strftime("%Y%m%d")

def parse_date(s: str) -> dt.date:
    s = str(s)
    if "-" in s:
        return dt.datetime.strptime(s, "%Y-%m-%d").date()
    return dt.datetime.strptime(s, "%Y%m%d").date()

@lru_cache(maxsize=512)
def _nearest_bizday_cached(date_ymd: str) -> str:
    return stock.get_nearest_business_day_in_a_week(date_ymd)

def is_trading_day(date: dt.date) -> bool:
    today = dt.date.today()
    if date == today:
        return date.weekday() < 5

    date_ymd = to_ymd(date)
    try:
        nearest = _nearest_bizday_cached(date_ymd)
        if nearest == date_ymd:
            return True
    except:
        pass

    try:
        df_tmp = fdr.DataReader("KS11", date, date)
        if df_tmp is not None and not df_tmp.empty:
            return True
    except:
        pass

    return date.weekday() < 5

def get_next_bizdate(last_date: dt.date) -> dt.date:
    d = last_date
    for _ in range(400):
        d = d + dt.timedelta(days=1)
        if is_trading_day(d):
            return d
    raise RuntimeError("ë‹¤ìŒ ì˜ì—…ì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ======================
# SAVE / LOAD
# ======================
def load_raw_main() -> pd.DataFrame:
    latest_path = find_latest_file(STOCKS_DIR, "all_stocks_cumulative")
    if latest_path and os.path.exists(latest_path):
        log(f"[INFO] ìµœì‹  RAW íŒŒì¼ ì‚¬ìš©: {os.path.basename(latest_path)}")
        df = pd.read_parquet(latest_path)
    else:
        if os.path.exists(RAW_MAIN):
            log(f"[INFO] íƒœê·¸ íŒŒì¼ ì—†ìŒ. ê¸°ì¡´ RAW_MAIN ì‚¬ìš©: {os.path.basename(RAW_MAIN)}")
            df = pd.read_parquet(RAW_MAIN)
        else:
            raise FileNotFoundError(f"RAW ë©”ì¸ íŒŒì¼ ì—†ìŒ: {RAW_MAIN} ë˜ëŠ” all_stocks_cumulative_*.parquet")

    df["Date"] = pd.to_datetime(df["Date"]).dt.date
    return df

def merge_daily_into_raw(raw_df: pd.DataFrame, daily_df: pd.DataFrame) -> pd.DataFrame:
    merged = pd.concat([raw_df, daily_df], ignore_index=True)
    merged = merged.drop_duplicates(subset=["Date", "Code"], keep="last")
    merged = merged.sort_values(["Date", "Code"]).reset_index(drop=True)
    return merged

# =====================================================================================
# [ë³µêµ¬] Kiwoom REST API ìˆ˜ì§‘ í•¨ìˆ˜
# =====================================================================================
def build_daily_from_kiwoom(date: dt.date, tickers: Optional[List[str]] = None) -> Tuple[pd.DataFrame, List[str]]:
    log(f"[STEP] KIWOOM ì „ì²´ ì¼ë´‰ ìˆ˜ì§‘ ì‹œì‘: {to_ymd(date)}")

    import configparser
    cfg = configparser.ConfigParser()
    cfg.read(r"F:\autostockG\kiwoom_rest\config.ini")

    MODE = cfg["SETTINGS"]["MODE"].strip().lower()
    BASE_URL = cfg["SETTINGS"]["BASE_URL_PAPER"] if MODE == "paper" else cfg["SETTINGS"]["BASE_URL"]

    token_mgr = KiwoomTokenManager(
        config_file=r"F:\autostockG\kiwoom_rest\config.ini",
        token_file=r"F:\autostockG\kiwoom_rest\token.json"
    )
    token = token_mgr.get_access_token()

    if tickers is None:
        try:
            tickers = stock.get_market_ticker_list(date=to_ymd(date), market="ALL")
        except:
            tickers = []
        if not tickers:
            try:
                tickers = load_raw_main()["Code"].unique().tolist()
            except:
                tickers = []

    rows = []
    bad_codes = []
    target = to_ymd(date)

    for idx, code in enumerate(tickers, 1):
        if idx % 100 == 0:
            log(f"[KIWOOM] ì§„í–‰ {idx}/{len(tickers)}")

        url = f"{BASE_URL}/api/dostk/chart"
        headers = {
            "Content-Type": "application/json;charset=UTF-8",
            "api-id": "ka10081",
            "authorization": f"Bearer {token}",
        }
        body = {
            "stk_cd": code,
            "base_dt": target,
            "upd_stkpc_tp": "0",
        }

        try:
            r = requests.post(url, headers=headers, json=body, timeout=2)
            r.raise_for_status()
            js = r.json()

            chart = js.get("stk_dt_pole_chart_qry") or js.get("chart") or []
            if not chart:
                bad_codes.append(code)
                continue

            matched = None
            for item in chart:
                if str(item.get("dt")) == target:
                    matched = item
                    break
            if matched is None:
                matched = chart[0]

            def _to_float(v):
                try:
                    return float(str(v).replace("+", "").replace(",", "").strip())
                except:
                    return float("nan")

            rows.append({
                "Date": date,
                "Open": _to_float(matched.get("open_pric")),
                "High": _to_float(matched.get("high_pric")),
                "Low": _to_float(matched.get("low_pric")),
                "Close": _to_float(matched.get("cur_prc")),
                "Volume": _to_float(matched.get("trde_qty")),
                "Change": 0.0,
                "Code": code,
                "Name": "",
                "Market": ""
            })

        except:
            bad_codes.append(code)

    df = pd.DataFrame(rows)
    log(f"[KIWOOM] {len(df)}ê°œ ì¢…ëª© ìˆ˜ì§‘, ì‹¤íŒ¨ {len(bad_codes)}ê°œ")
    return df, bad_codes

# =====================================================================================
# [ë³µêµ¬] pykrx ìˆ˜ì§‘ í•¨ìˆ˜
# =====================================================================================
def build_daily_from_pykrx(date: dt.date) -> Tuple[pd.DataFrame, List[str]]:
    for key in ["http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY"]:
        _os.environ[key] = ""

    date_ymd = to_ymd(date)
    log(f"[STEP] KRX ì¼ê´„ ìˆ˜ì§‘ ì‹œì‘: {date_ymd}")

    df = stock.get_market_ohlcv_by_ticker(date_ymd, market="ALL")
    if df is None or df.empty:
        raise RuntimeError(f"KRX ë°ì´í„° ì—†ìŒ: {date_ymd}")

    rename_map = {"ì‹œê°€": "Open", "ê³ ê°€": "High", "ì €ê°€": "Low", "ì¢…ê°€": "Close", "ê±°ë˜ëŸ‰": "Volume"}
    df = df.rename(columns=rename_map)

    if "ë“±ë½ë¥ " in df.columns:
        df["Change"] = df["ë“±ë½ë¥ "] / 100.0
    else:
        df["Change"] = 0.0

    df = df.reset_index().rename(columns={"í‹°ì»¤": "Code"})

    def _get_name_safe(ticker):
        try:
            return stock.get_market_ticker_name(ticker)
        except:
            return ""

    df["Name"] = df["Code"].map(_get_name_safe)
    df["Date"] = date

    keep_cols = ["Date", "Open", "High", "Low", "Close", "Volume", "Change", "Code", "Name"]
    for col in keep_cols:
        if col not in df.columns:
            df[col] = pd.NA
    df = df[keep_cols]

    mask_bad = _invalid_ohlcv_mask(df)
    suspicious = df.loc[mask_bad, "Code"].tolist()
    log(f"[KRX] {len(df)}ê°œ ì¢…ëª© ìˆ˜ì§‘, ì˜ì‹¬ {len(suspicious)}ê°œ")
    return df, suspicious

# =====================================================================================
# [ë³µêµ¬] ë³´ì¡° ìˆ˜ì§‘
# =====================================================================================
def fetch_ohlcv_from_naver(ticker, yyyymmdd):
    url = f"https://api.finance.naver.com/siseJson.naver?symbol={ticker}&requestType=1&startTime={yyyymmdd}&endTime={yyyymmdd}"
    try:
        r = requests.get(url, timeout=5)
        arr = r.json()
        if not arr or len(arr) < 2:
            return None
        row = arr[1]
        return {
            "Open": float(row[1]), "High": float(row[2]),
            "Low": float(row[3]), "Close": float(row[4]),
            "Volume": float(row[5]),
        }
    except:
        return None

def fetch_ohlcv_from_fdr(ticker, yyyymmdd):
    try:
        d0 = dt.datetime.strptime(yyyymmdd, "%Y%m%d").date()
        d1 = d0 + dt.timedelta(days=1)
        df = fdr.DataReader(ticker, d0, d1)
        if df is None or df.empty:
            return None
        row = df.iloc[0]
        return {
            "Open": float(row["Open"]), "High": float(row["High"]),
            "Low": float(row["Low"]), "Close": float(row["Close"]),
            "Volume": float(row["Volume"]),
        }
    except:
        return None

def fetch_ohlcv_from_yahoo(ticker, yyyymmdd):
    try:
        d0 = dt.datetime.strptime(yyyymmdd, "%Y%m%d").date()
        d1 = d0 + dt.timedelta(days=1)
        for suffix in [".KS", ".KQ", ""]:
            df = yf.download(f"{ticker}{suffix}", start=d0, end=d1, progress=False)
            if df is None or df.empty:
                continue
            row = df.iloc[0]
            return {
                "Open": float(row["Open"]), "High": float(row["High"]),
                "Low": float(row["Low"]), "Close": float(row["Close"]),
                "Volume": float(row["Volume"]),
            }
        return None
    except:
        return None

FALLBACK_SOURCES = [
    ("fdr", fetch_ohlcv_from_fdr),
    ("yahoo", fetch_ohlcv_from_yahoo),
    ("naver", fetch_ohlcv_from_naver),
]

def fill_missing_with_sources(daily_df, date, codes, sources=None):
    if not codes:
        return daily_df, []
    if sources is None:
        sources = FALLBACK_SOURCES

    date_ymd = to_ymd(date)
    unresolved = list(dict.fromkeys(codes))

    for source_name, fetcher in sources:
        if not unresolved:
            break
        log(f"[{source_name.upper()}] ë³´ì¡° ìˆ˜ì§‘ ì‹œì‘ ({len(unresolved)}ê°œ)")

        still = []
        updated = {}

        for code in unresolved:
            o = fetcher(code, date_ymd)
            if not o:
                still.append(code)
                continue
            updated[code] = o

        for code, o in updated.items():
            idx = daily_df.index[daily_df["Code"] == code].tolist()
            if idx:
                for col in ["Open", "High", "Low", "Close", "Volume"]:
                    daily_df.at[idx[0], col] = o[col]
                daily_df.at[idx[0], "Change"] = 0.0

        unresolved = still
        log(f"[{source_name.upper()}] ë‚¨ì€ ì½”ë“œëŠ” {len(unresolved)}ê°œ")

    return daily_df, unresolved

def build_daily_from_fallback_sources(date, tickers):
    tickers = list(dict.fromkeys(tickers))
    base = pd.DataFrame({"Code": tickers})
    base["Date"] = date
    for col in ["Open","High","Low","Close","Volume","Change","Name"]:
        if col not in base.columns:
            base[col] = pd.NA

    df, unresolved = fill_missing_with_sources(base, date, tickers)
    mask_bad = _invalid_ohlcv_mask(df)
    unresolved = list(dict.fromkeys(unresolved + df.loc[mask_bad, "Code"].tolist()))
    log(f"[FALLBACK] ì„±ê³µ {len(df) - len(unresolved)}ê±´, ì‹¤íŒ¨ {len(unresolved)}ê±´")
    return df, unresolved


# =====================================================================================
# â­ ë©”ì¸ ì‹¤í–‰ë¶€
# =====================================================================================
if __name__ == "__main__":
    print_header()

    now_dt = dt.datetime.now()
    today = now_dt.date()
    raw_df = load_raw_main()

    last_date = raw_df["Date"].max()
    log(f"[STEP 1] RAW ìµœì‹  ë‚ ì§œ: {last_date}")

    # 16~18ì‹œëŠ” ì˜¤ì—¼ë°©ì§€ë¡œ ì¤‘ë‹¨
    if dt.time(16,0) <= now_dt.time() < dt.time(18,0):
        log("[WARN] 16~18ì‹œëŠ” ì „ë‚  ì˜ì—…ì¼ ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.")
        # continue without exit

    # ======================================================================
    # >>>>>>>>>>>>>>>>>>>>>>>>>> PATCH START (target_date ì¬ì„¤ê³„) <<<<<<<<<<<<<<<<<<<<<<<<<
    # ======================================================================

    try:
        now_t = now_dt.time()

        # todayê°€ íœ´ì¼ì´ë©´ ìµœê·¼ ì˜ì—…ì¼ë¡œ ì¡°ì •
        try:
            nearest = stock.get_nearest_business_day_in_a_week(to_ymd(today))
            today_biz = parse_date(nearest)
        except:
            tmp = today
            while not is_trading_day(tmp):
                tmp = tmp - dt.timedelta(days=1)
            today_biz = tmp

        # ì „ë‚  ì˜ì—…ì¼ ê³„ì‚°
        prev_biz = today_biz
        while True:
            prev_biz = prev_biz - dt.timedelta(days=1)
            if is_trading_day(prev_biz):
                break

        # ì‹œê°„ëŒ€ ë£° ì ìš©
        if not is_trading_day(today):
            target_date = today_biz
        elif dt.time(16,0) <= now_t < dt.time(18,0):
            log("[WARN] 16~18ì‹œëŠ” ì „ë‚  ì˜ì—…ì¼ ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.")
            target_date = prev_biz
        elif now_t < dt.time(18,0):
            target_date = prev_biz
        else:
            target_date = today_biz

    except Exception as e:
        raise e


    # ì‹¤ì œ ì—…ë°ì´íŠ¸ ë²”ìœ„ ë¡œê·¸(ì •í™• í‘œê¸°)
    log(f"[STEP 2] ì‹¤ì œ ì—…ë°ì´íŠ¸ ë²”ìœ„: {dates_to_update[0]} ~ {dates_to_update[-1]}")

    # ======================================================================
    # >>>>>>>>>>>>>>>>>>>>>>>>>> PATCH END <<<<<<<<<<<<<<<<<<<<<<<<<
    # ======================================================================

    # ----------------------- ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ -----------------------
    # ì›ë³¸ daily ì²˜ë¦¬ ë¸”ë¡ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ for-loop ì ìš©
    for date in dates_to_update:
        log(f"[LOOP] {date} ì—…ë°ì´íŠ¸ ì‹œì‘")

        # ===========================
        # â­â­ 1ìˆœìœ„: pykrx
        # ===========================
        try:
            daily_df, bad_codes = build_daily_from_pykrx(date)
            log("[OK] KRX(pykrx) ë°ì´í„° ì‚¬ìš©")
        except Exception as e:
            log(f"[WARN] KRX(pykrx) ì‹¤íŒ¨ â†’ {e}")
            daily_df = None
            bad_codes = []

        # ===========================
        # â­â­ 2ìˆœìœ„: KIWOOM
        # ===========================
        if daily_df is None or daily_df.empty:
            try:
                daily_df, bad_codes = build_daily_from_kiwoom(date)
                log("[OK] KIWOOM ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ. 2ìˆœìœ„ ì†ŒìŠ¤ë¡œ ì‚¬ìš©.")
            except Exception as e:
                log(f"[WARN] KIWOOM ì‹¤íŒ¨ â†’ {e}")
                daily_df = None
                bad_codes = []

        # â­â­ 3ìˆœìœ„: fallback
        if daily_df is None or daily_df.empty:
            tickers = raw_df["Code"].unique().tolist()
            daily_df, bad_codes = build_daily_from_fallback_sources(date, tickers)
            if daily_df is None or daily_df.empty:
                log("[ERROR] FDR/Yahoo/Naver fallback ì‹¤íŒ¨")
                continue
            else:
                log("[OK] FDR/Yahoo/Naver fallback ì‚¬ìš©")

        # ë¶€ì¡±ë¶„ ë³´ì¡° ìˆ˜ì§‘
        if bad_codes:
            try:
                kiw_df, _ = build_daily_from_kiwoom(date, tickers=bad_codes)
                if kiw_df is not None and not kiw_df.empty:
                    kiw_sub = kiw_df[kiw_df["Code"].isin(bad_codes)]
                    if not kiw_sub.empty:
                        daily_df = merge_daily_into_raw(daily_df, kiw_sub)
                        log(f"[KIWOOM] ë³´ì¡° ìˆ˜ì§‘ìœ¼ë¡œ {len(kiw_sub)}ê°œ ë®ì–´ì”€")
            except Exception as e:
                log(f"[WARN] KIWOOM ë³´ì¡° ìˆ˜ì§‘ ì‹¤íŒ¨ â†’ {e}")

        # SAVE DAILY
        out_path = os.path.join(DAILY_DIR, f"daily_{date.strftime('%y%m%d')}.parquet")
        daily_df.to_parquet(out_path)
        log(f"[SAVE] DAILY ì €ì¥ ì™„ë£Œ: {out_path}")

        # RAW ë³‘í•©
        raw_df = merge_daily_into_raw(raw_df, daily_df)

        # (ë³€ê²½) RAW ìµœì‹ ë³¸ ì €ì¥ì€ ë£¨í”„ ì¢…ë£Œ í›„ 1íšŒ ìˆ˜í–‰

    # ë£¨í”„ ì¢…ë£Œ í›„ RAW ìµœì‹ ë³¸ì„ 1íšŒ ì €ì¥ (ëˆ„ì  ë³‘í•© ê²°ê³¼)
    saved_path = save_dataframe_with_date(raw_df, STOCKS_DIR, "all_stocks_cumulative", date_col="Date")
    if saved_path:
        log(f"[SAVE] RAW ìµœì‹ ë³¸ ì €ì¥: {os.path.basename(saved_path)}")
    else:
        log("[SKIP] RAW ìµœì‹ ë³¸ ì €ì¥ ê±´ë„ˆëœ€ (ë™ì¼ ë‚ ì§œ íŒŒì¼ ì¡´ì¬)")

    log("[DONE] RAW ì—…ë°ì´íŠ¸ ë.")
