# ============================================================
# Unified HOJ Trainer (V32) - The Engine Factory
#   - í†µí•© DB(HOJ_DB_V31.parquet) í•˜ë‚˜ë¡œ Real/Research ëª¨ë‘ ì²˜ë¦¬
#   - ë™ì  íƒ€ê²Ÿ ìƒì„± (Horizon ììœ  ì¡°ì ˆ)
#   - ì—„ê²©í•œ íŒŒì¼ëª… ê·œì¹™ ì ìš© (d:ë°ì´í„°ë‚ ì§œ, t:í•™ìŠµë‚ ì§œ)
# ============================================================

import os
import sys
import pickle
import argparse
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
import lightgbm as lgb

# ------------------------------------------------------------
# 1. í”„ë¡œì íŠ¸ í™˜ê²½ ì„¤ì • (ê¸°ì¡´ ìœ í‹¸ ì—°ê²°)
# ------------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)  # MODELENGINE
root_dir = os.path.dirname(parent_dir)     # Root
sys.path.append(root_dir)

try:
    from MODELENGINE.UTIL.config_paths import get_path
    from MODELENGINE.UTIL.version_utils import backup_existing_file
except ImportError:
    # UTIL í´ë” ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë  ê²½ìš°ë¥¼ ëŒ€ë¹„
    sys.path.append(parent_dir)
    from UTIL.config_paths import get_path
    from UTIL.version_utils import backup_existing_file

# ------------------------------------------------------------
# 2. í•µì‹¬ í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------------

def get_db_path(version="V31"):
    """
    [ê·œì¹™ ë³€ê²½ ë°˜ì˜]
    DBëŠ” ì´ì œ 'HOJ_DB' í´ë” ë°”ë¡œ ì•„ë˜ì— í†µí•© íŒŒì¼ í•˜ë‚˜ë§Œ ì¡´ì¬í•¨.
    ì˜ˆ: MODELENGINE/HOJ_DB/HOJ_DB_V31.parquet
    """
    base_dir = get_path("HOJ_DB") # ë³´í†µ .../MODELENGINE/HOJ_DB
    # config_pathsê°€ í•˜ìœ„í´ë”(REAL/RESEARCH)ë¥¼ ê°€ë¦¬í‚¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìƒìœ„ë¡œ í•œ ë²ˆ ë³´ì •
    if "REAL" in base_dir or "RESEARCH" in base_dir:
        base_dir = os.path.dirname(base_dir)
        
    db_name = f"HOJ_DB_{version}.parquet"
    db_path = os.path.join(base_dir, db_name)
    return db_path

def ensure_datetime(df, col="Date"):
    if not np.issubdtype(df[col].dtype, np.datetime64):
        df[col] = pd.to_datetime(df[col], errors="coerce")
    return df

def build_dynamic_target(df: pd.DataFrame, horizon: int) -> pd.DataFrame:
    """
    ìš”ì²­í•œ Horizon(ì˜ˆ: 3ì¼)ì— ë§ëŠ” ì •ë‹µì§€(Return_3d)ê°€ ì—†ìœ¼ë©´
    Close ë°ì´í„°ë¥¼ ì´ìš©í•´ ì¦‰ì„ì—ì„œ ë§Œë“¤ì–´ëƒ„.
    """
    ret_col = f"Return_{horizon}d"
    lab_col = f"Label_{horizon}d"

    if ret_col in df.columns and lab_col in df.columns:
        return df

    print(f"  âš¡ [Auto-Gen] '{ret_col}' íƒ€ê²Ÿ ìƒì„± ì¤‘ (Horizon={horizon})...")
    
    if "Close" not in df.columns:
        raise KeyError("DBì— 'Close' ì»¬ëŸ¼ì´ ì—†ì–´ íƒ€ê²Ÿì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    df = df.sort_values(["Code", "Date"]).copy()
    
    # ìˆ˜ìµë¥  = (ë¯¸ë˜ hì¼ ì¢…ê°€ / ì˜¤ëŠ˜ ì¢…ê°€) - 1
    # groupby().shift() ì‚¬ìš©
    df[ret_col] = df.groupby("Code")["Close"].shift(-horizon) / df["Close"] - 1.0
    
    # ë¼ë²¨ = ìˆ˜ìµë¥  > 0 (1 or 0)
    df[lab_col] = (df[ret_col] > 0).astype(int)
    
    return df

def get_save_filename(mode, version, data_date, horizon, n_estimators, train_date):
    """
    [íŒŒì¼ëª… ê·œì¹™ í™•ì •ì•ˆ]
    HOJ_ENGINE_{MODE}_{VER}_d{DATA}_h{HOR}_n{TREES}_t{TRAIN}.pkl
    """
    name = (
        f"HOJ_ENGINE_{mode.upper()}_{version}_"
        f"d{data_date}_"     # ë°ì´í„° ë§ˆì§€ë§‰ ë‚ ì§œ (Sync Checkìš©)
        f"h{horizon}_"       # ì˜ˆì¸¡ ê¸°ê°„
        f"n{n_estimators}_"  # í•™ìŠµ ê°•ë„
        f"t{train_date}"     # ì‹¤ì œ í•™ìŠµ ìˆ˜í–‰ì¼
        ".pkl"
    )
    return name

# ------------------------------------------------------------
# 3. ë©”ì¸ íŠ¸ë ˆì´ë‹ ë¡œì§
# ------------------------------------------------------------
def run_unified_training(
    mode="research",
    horizon=5,
    valid_days=365,
    n_estimators=1000,
    version="V31"
):
    mode = mode.lower()
    print(f"\n=== ğŸ­ [HOJ Engine Factory] ê°€ë™ ì‹œì‘ ({mode.upper()}) ===")
    print(f"  âš™ï¸ ì„¤ì •: Horizon={horizon}d | Valid={valid_days}d | Trees={n_estimators}")

    # [A] í†µí•© DB ë¡œë“œ
    db_path = get_db_path(version)
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"âŒ DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}\n   -> 1ë‹¨ê³„(ë°ì´í„° ì—…ë°ì´íŠ¸)ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    
    print(f"  ğŸ“‚ DB ë¡œë”©: {os.path.basename(db_path)}")
    df = pd.read_parquet(db_path)
    df = ensure_datetime(df)
    df = df.sort_values(["Date", "Code"]).reset_index(drop=True)

    # [B] ë°ì´í„° ì •ë³´ í™•ì¸ (ë‚ ì§œ ê¸°ì¤€ì )
    min_date = df["Date"].min().date()
    max_date_obj = df["Date"].max()
    max_date = max_date_obj.date()
    
    # íŒŒì¼ëª…ì— ì“¸ 'd' íƒœê·¸ (ë°ì´í„° ë‚ ì§œ)
    data_date_tag = max_date.strftime("%y%m%d")
    
    print(f"  ğŸ“… ë°ì´í„° ê¸°ê°„: {min_date} ~ {max_date} (Total {len(df):,} rows)")
    print(f"  ğŸ·ï¸ ë°ì´í„° ë²„ì „ íƒœê·¸: d{data_date_tag}")

    # [C] íƒ€ê²Ÿ(ì •ë‹µ) ì¤€ë¹„
    df = build_dynamic_target(df, horizon)
    ret_col = f"Return_{horizon}d"
    lab_col = f"Label_{horizon}d"

    # [D] í”¼ì²˜ ì„ ì • (ìˆ˜ì¹˜í˜•ë§Œ ìë™ ì„ íƒ, ë©”íƒ€ë°ì´í„° ì œì™¸)
    exclude_cols = [
        "Code", "Date", "Name", "Market", 
        "Open", "High", "Low", "Close", "Volume", "Amount", "Marcap",
        "KOSPI_ì¢…ê°€", "KOSPI_ìˆ˜ìµë¥ ",
        ret_col, lab_col, f"Expected_{ret_col}"
    ]
    # ë‹¤ë¥¸ horizon ë¼ë²¨ë“¤ë„ í•™ìŠµì—ì„œ ë°°ì œ
    exclude_cols += [c for c in df.columns if (c.startswith("Return_") or c.startswith("Label_"))]

    feature_cols = df.columns.difference(exclude_cols).tolist()
    # float, int, bool íƒ€ì…ë§Œ ë‚¨ê¸°ê¸°
    feature_cols = df[feature_cols].select_dtypes(include=["number", "bool"]).columns.tolist()
    
    if not feature_cols:
        raise ValueError("âŒ í•™ìŠµí•  í”¼ì²˜ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤! DB ì»¬ëŸ¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    print(f"  ğŸ§¬ í•™ìŠµ í”¼ì²˜ ({len(feature_cols)}ê°œ): {feature_cols[:5]} ...")

    # [E] ê²°ì¸¡ ì œê±° (í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±)
    # í”¼ì²˜ë‚˜ íƒ€ê²Ÿì´ ì—†ëŠ” í–‰ì€ í•™ìŠµ ë¶ˆê°€ -> ì œê±°
    mask = df[feature_cols].notnull().all(axis=1) & df[ret_col].notnull()
    df_train = df[mask].copy()
    
    print(f"  ğŸ§¹ NaN ì œê±° í›„ í•™ìŠµ ìƒ˜í”Œ: {len(df_train):,} rows")

    # [F] ëª¨ë“œë³„ ë¶„í•  ë° í•™ìŠµ ì„¤ì •
    X_valid = None
    metrics = {}
    
    params_common = {
        "n_estimators": n_estimators,
        "learning_rate": 0.03,
        "num_leaves": 63,
        "feature_fraction": 0.9,
        "bagging_fraction": 0.9,
        "bagging_freq": 3,
        "n_jobs": -1,
        "verbose": -1,
        "random_state": 42
    }

    if mode == "research":
        # ê²€ì¦ì…‹ ë¶„ë¦¬ (ë’¤ì—ì„œ valid_days ë§Œí¼)
        split_date = max_date_obj - timedelta(days=valid_days)
        print(f"  ğŸ§ª Research Mode: ê²€ì¦ êµ¬ê°„ ë¶„ë¦¬ ({valid_days}ì¼)")
        print(f"     Split Date: {split_date.date()}")
        
        mask_tr = df_train["Date"] < split_date
        mask_va = df_train["Date"] >= split_date
        
        X_tr = df_train.loc[mask_tr, feature_cols]
        y_tr_reg = df_train.loc[mask_tr, ret_col]
        y_tr_cls = df_train.loc[mask_tr, lab_col]
        
        X_va = df_train.loc[mask_va, feature_cols]
        y_va_reg = df_train.loc[mask_va, ret_col]
        y_va_cls = df_train.loc[mask_va, lab_col]
        
        print(f"     Train: {len(X_tr):,} / Valid: {len(X_va):,}")
        
        # í•™ìŠµ (Early Stopping ì ìš©)
        print("  ğŸ¤– íšŒê·€ ëª¨ë¸(Regressor) í•™ìŠµ ì¤‘...")
        model_reg = lgb.LGBMRegressor(objective="regression", metric="rmse", **params_common)
        model_reg.fit(X_tr, y_tr_reg, eval_set=[(X_va, y_va_reg)], 
                      callbacks=[lgb.early_stopping(100, verbose=False)])
        
        print("  ğŸ¤– ë¶„ë¥˜ ëª¨ë¸(Classifier) í•™ìŠµ ì¤‘...")
        model_cls = lgb.LGBMClassifier(objective="binary", metric="binary_logloss", **params_common)
        model_cls.fit(X_tr, y_tr_cls, eval_set=[(X_va, y_va_cls)], 
                      callbacks=[lgb.early_stopping(100, verbose=False)])
        
        # ì„±ëŠ¥ ì¸¡ì •
        rmse = np.sqrt(np.mean((model_reg.predict(X_va) - y_va_reg) ** 2))
        acc = np.mean(model_cls.predict(X_va) == y_va_cls)
        print(f"  ğŸ“Š [ê²€ì¦ ê²°ê³¼] RMSE: {rmse:.5f} | ACC: {acc:.2%}")
        metrics = {"rmse": rmse, "acc": acc}
        
        X_valid = X_va # ì €ì¥ìš© ì°¸ì¡°

    else: # REAL Mode
        print("  ğŸš€ Real Mode: ì „ì²´ ë°ì´í„° í•™ìŠµ (No Valid Split)")
        X_tr = df_train[feature_cols]
        y_tr_reg = df_train[ret_col]
        y_tr_cls = df_train[lab_col]
        
        print("  ğŸ¤– ì „ì²´ ë°ì´í„° í•™ìŠµ ì¤‘...")
        model_reg = lgb.LGBMRegressor(objective="regression", metric="rmse", **params_common)
        model_reg.fit(X_tr, y_tr_reg)
        
        model_cls = lgb.LGBMClassifier(objective="binary", metric="binary_logloss", **params_common)
        model_cls.fit(X_tr, y_tr_cls)
        
        metrics = {"note": "Real mode trained on full data"}

    # [G] ì €ì¥ (íŒŒì¼ëª… ê·œì¹™ ì ìš©)
    train_date_tag = datetime.now().strftime("%y%m%d") # ì˜¤ëŠ˜ ë‚ ì§œ t
    save_name = get_save_filename(mode, version, data_date_tag, horizon, n_estimators, train_date_tag)
    
    # ì €ì¥ ê²½ë¡œ (Real / Research í´ë” ìœ ì§€)
    save_dir = get_path("HOJ_ENGINE", mode.upper())
    save_path = os.path.join(save_dir, save_name)
    
    # ë©”íƒ€ë°ì´í„° íŒ¨í‚¤ì§•
    payload = {
        "model_reg": model_reg,
        "model_cls": model_cls,
        "features": feature_cols,
        "meta": {
            "mode": mode,
            "version": version,
            "horizon": horizon,
            "valid_days": valid_days if mode == 'research' else 0,
            "n_estimators": n_estimators,
            "data_date": str(max_date),
            "train_date": str(datetime.now().date()),
            "metrics": metrics
        }
    }
    
    with open(save_path, "wb") as f:
        pickle.dump(payload, f)
        
    print(f"\nğŸ’¾ ì—”ì§„ ì €ì¥ ì™„ë£Œ:")
    print(f"   ğŸ“ ê²½ë¡œ: {save_path}")
    print(f"   ğŸ·ï¸ íŒŒì¼ëª…: {save_name}")
    print("=== ğŸ Factory Operation Complete ===")

# ------------------------------------------------------------
# 4. CLI ì‹¤í–‰ë¶€
# ------------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", default="research", choices=["real", "research"])
    parser.add_argument("--horizon", type=int, default=5)
    parser.add_argument("--valid_days", type=int, default=365)
    parser.add_argument("--n_estimators", type=int, default=1000)
    parser.add_argument("--version", type=str, default="V31")
    
    args = parser.parse_args()
    
    try:
        run_unified_training(
            mode=args.mode,
            horizon=args.horizon,
            valid_days=args.valid_days,
            n_estimators=args.n_estimators,
            version=args.version
        )
    except Exception as e:
        print(f"\nâŒ [Error] {e}")