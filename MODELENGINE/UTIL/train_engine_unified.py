# ============================================================
# train_engine_unified_V31_complete.py
#  - ÌÜµÌï© DB ÌïòÎÇò(HOJ_DB_V31.*)Î°ú REAL/RESEARCH Î™®Îëê ÌïôÏäµ
#  - AÏïà: ÏÑ†ÌÉù ÌîºÏ≤òÏùò 'ÏµúÎåÄ Í∏∞Í∞Ñ'ÎßåÌÅº Í∞Å Ï¢ÖÎ™© ÏïûÍµ¨Í∞Ñ Ï†úÍ±∞(Ï¥àÍ∏∞ Ïò§Ïóº 0%)
#  - Horizon Tail: Í∞Å Ï¢ÖÎ™© Îí§ÏóêÏÑú hÏùº Ï†úÍ±∞(ÎØ∏ÎûòÏ†ïÎ≥¥ ÎàÑÏàò 0%)
#  - input_window: 0Ïù¥Î©¥ Ï†ÑÏ≤¥ ÌîºÏ≤ò ÏÇ¨Ïö©, >0Ïù¥Î©¥ Í∏∞Í∞Ñ Ï¥àÍ≥º ÏßÄÌëú Ï†úÏô∏
#  - Close/ClosePrice ÏûêÎèô Ïù∏ÏãùÏúºÎ°ú ÌÉÄÍ≤ü ÏÉùÏÑ±
#  - meta Ï†ÄÏû•: feature_hash, data_date, horizon, input_window, valid_days Îì±
#  - Ï†ÄÏû• Í∑úÏπô: MODELENGINE/HOJ_ENGINE/{REAL|RESEARCH}/HOJ_ENGINE_{MODE}_{...}.pkl
#  - [Ï∂îÍ∞Ä] Ïã§Ìñâ Ïãú Research -> Real ÏàúÏ∞® ÏûêÎèô Ïã§Ìñâ ÏßÄÏõê
# ============================================================

import os
import sys
import re
INT_PAT = re.compile(r"\d+")
import pickle
import argparse
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
import lightgbm as lgb

# ------------------------------------------------------------
# 0) Í≤ΩÎ°ú Ïú†Ìã∏
# ------------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
modelengine_dir = os.path.dirname(current_dir)
root_dir = os.path.dirname(modelengine_dir)
sys.path.extend([root_dir, modelengine_dir])

def _try_import_paths():
    HOJ_DB, HOJ_ENGINE_REAL, HOJ_ENGINE_RESEARCH, OUTPUT = None, None, None, None
    try:
        from MODELENGINE.UTIL.config_paths import get_path
        from MODELENGINE.UTIL.version_utils import find_latest_file
        def _get(purpose, *args): return get_path(purpose, *args)
        _find = find_latest_file
    except Exception:
        def _get(purpose, *args):
            base = os.path.join(root_dir, "MODELENGINE")
            if purpose == "HOJ_DB":
                return os.path.join(base, "HOJ_DB")
            if purpose == "HOJ_ENGINE":
                return os.path.join(base, "HOJ_ENGINE")
            if purpose == "OUTPUT":
                return os.path.join(base, "OUTPUT")
            return os.path.join(base, "HOJ_ENGINE", args[0]) if args else os.path.join(base, "HOJ_ENGINE")

        def _find(folder, prefix):
            if not os.path.isdir(folder):
                return None
            cand = [os.path.join(folder, f) for f in os.listdir(folder) if f.startswith(prefix)]
            return sorted(cand)[-1] if cand else None

    return _get, _find

get_path, find_latest_file = _try_import_paths()

def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)
    return path

# ------------------------------------------------------------
# LightGBM ÏΩúÎ∞±
# ------------------------------------------------------------
def single_line_logger(period=50):
    def _callback(env):
        if period > 0 and env.iteration % period == 0:
            if env.evaluation_result_list:
                name, metric, value, _ = env.evaluation_result_list[0]
                msg = f"[{env.iteration}] {name}-{metric}: {value:.6f}"
                print("\r" + msg, end="", flush=True)
            if env.iteration == env.end_iteration - 1:
                print()
    _callback.order = 10
    return _callback

# ------------------------------------------------------------
# 1) Îç∞Ïù¥ÌÑ∞ Î°úÎìú
# ------------------------------------------------------------
NUM_DTYPES = ("int", "uint", "float", "double")

NON_FEATURE_CANDIDATES = {
    "Date","date","Code","code","Name","name",
    "Open","High","Low","Close","ClosePrice","Adj Close","AdjClose",
    "Volume","Amount","open","high","low","close","volume","amount",
    "KOSPI_Close","KOSPI_Change"
}

def pick_close_column(df: pd.DataFrame) -> str:
    for c in ["Close","ClosePrice","Adj Close","AdjClose","close"]:
        if c in df.columns:
            return c
    raise KeyError("Close Ïª¨Îüº ÏóÜÏùå")

def load_latest_db(version: str = "V31") -> pd.DataFrame:
    base_dir = get_path("HOJ_DB")
    if "REAL" in base_dir or "RESEARCH" in base_dir:
        base_dir = os.path.dirname(base_dir)

    latest = find_latest_file(base_dir, f"HOJ_DB_{version}")
    if latest is None:
        cand = os.path.join(base_dir, f"HOJ_DB_{version}.parquet")
        if not os.path.exists(cand):
            raise FileNotFoundError(f"HOJ_DB ÌååÏùº ÏóÜÏùå: {base_dir}")
        return pd.read_parquet(cand)

    return pd.read_parquet(latest)

def select_feature_columns(df):
    drop_cols = [
        'Date','Code','Open','High','Low','Close','Volume',
        'Return_1d','Return_5d','Label_1d','Label_5d',
        'KOSPI_Close','KOSPI_Change'
    ]
    feats = []
    for col in df.columns:
        if col in drop_cols:
            continue
        if str(df[col].dtype).startswith(("float","int")):
            feats.append(col)
    return feats

def feature_period(col: str) -> int:
    m = [int(x) for x in INT_PAT.findall(col)]
    return max(m) if m else 0

def apply_A_mask(df: pd.DataFrame, features: list, input_window: int, close_col: str, horizon: int):
    if input_window and input_window > 0:
        feats = []
        for c in features:
            p = feature_period(c)
            if (p == 0) or (p <= input_window):
                feats.append(c)
        features = feats

    max_period = max([feature_period(c) for c in features] + [0])

    parts = []
    for code, g in df.groupby("Code", sort=False):
        g = g.sort_values("Date")
        if max_period > 0:
            g = g.iloc[max_period:].copy()
        if horizon > 0:
            g = g.iloc[:-horizon] if len(g) > horizon else g.iloc[0:0]
        parts.append(g)

    df_m = pd.concat(parts, ignore_index=True) if parts else df.iloc[0:0].copy()
    df_m["TargetRet"] = df_m.groupby("Code")[close_col].shift(-horizon) / df_m[close_col] - 1.0
    df_m["TargetUp"] = (df_m["TargetRet"] > 0).astype("int8")

    use_cols = ["Date","Code", close_col] + features + ["TargetRet","TargetUp"]
    df_m = df_m[use_cols].dropna(subset=features + ["TargetRet"])
    return df_m, features, max_period

# ------------------------------------------------------------
# 3) Ïä§ÌîåÎ¶ø & ÌïôÏäµ
# ------------------------------------------------------------
def split_train_valid(df: pd.DataFrame, valid_days: int) -> tuple:
    max_day = df["Date"].max().normalize()
    valid_start = max_day - timedelta(days=int(valid_days))
    is_valid = df["Date"] >= valid_start
    train = df.loc[~is_valid].copy()
    valid = df.loc[ is_valid].copy()
    return train, valid, valid_start.date(), max_day.date()

def train_models(df_m: pd.DataFrame, features: list, n_estimators: int = 1000):
    X_tr = df_m.loc[df_m["is_train"], features]
    y_reg_tr = df_m.loc[df_m["is_train"], "TargetRet"]
    y_cls_tr = df_m.loc[df_m["is_train"], "TargetUp"]

    X_va = df_m.loc[~df_m["is_train"], features]
    y_reg_va = df_m.loc[~df_m["is_train"], "TargetRet"]
    y_cls_va = df_m.loc[~df_m["is_train"], "TargetUp"]

    model_reg = lgb.LGBMRegressor(
        n_estimators=n_estimators, max_depth=-1, learning_rate=0.03,
        subsample=0.9, colsample_bytree=0.9, objective="regression",
        n_jobs=-1
    )
    if len(X_va) > 0:
        model_reg.fit(X_tr, y_reg_tr,
            eval_set=[(X_va, y_reg_va)], eval_metric="rmse",
            callbacks=[single_line_logger(period=50)]
        )
    else:
        model_reg.fit(X_tr, y_reg_tr)

    model_cls = lgb.LGBMClassifier(
        n_estimators=n_estimators, max_depth=-1, learning_rate=0.03,
        subsample=0.9, colsample_bytree=0.9, objective="binary",
        n_jobs=-1
    )
    if len(X_va) > 0:
        model_cls.fit(X_tr, y_cls_tr,
            eval_set=[(X_va, y_cls_va)], eval_metric="auc",
            callbacks=[single_line_logger(period=50)]
        )
    else:
        model_cls.fit(X_tr, y_cls_tr)

    return model_reg, model_cls

# ------------------------------------------------------------
# 4) Ï†ÄÏû•
# ------------------------------------------------------------
def _hash_list(lst: list) -> str:
    return str(abs(hash("|".join(map(str, lst)))))

def save_engine(payload: dict, mode: str):
    base = get_path("HOJ_ENGINE")
    if os.path.isfile(base):
        base = os.path.dirname(base)

    out_dir = os.path.join(base, mode.upper())
    ensure_dir(out_dir)

    tag = datetime.strptime(payload["meta"]["data_date"], "%Y-%m-%d").strftime("%y%m%d")

    fname = (
        f"HOJ_ENGINE_{mode.upper()}_V31"
        f"_h{payload['meta']['horizon']}"
        f"_w{payload['meta']['input_window']}"
        f"_n{payload['meta']['n_estimators']}"
        f"_{tag}.pkl"
    )

    path = os.path.join(out_dir, fname)
    with open(path, "wb") as f:
        pickle.dump(payload, f)

    print(f"\nüíæ ÏóîÏßÑ Ï†ÄÏû• ÏôÑÎ£å: {path}")

# ------------------------------------------------------------
# 5) Î©îÏù∏ Ïã§Ìñâ
# ------------------------------------------------------------
def run_unified_training(
    mode: str = "research",
    horizon: int = 5,
    input_window: int = 60,
    valid_days: int = 365,
    n_estimators: int = 1000,
    version: str = "V31",
):
    assert mode in ("real","research")

    print(f"=== üöÄ Unified HOJ Trainer V31 ({mode.upper()}) ===")
    print(f"[CFG] mode={mode}  horizon={horizon}  input_window={input_window}  valid_days={valid_days}  n_estimators={n_estimators}")

    # 1) DB Î°úÎìú
    df = load_latest_db(version)
    close_col = pick_close_column(df)

    if not pd.api.types.is_datetime64_any_dtype(df["Date"]):
        df["Date"] = pd.to_datetime(df["Date"])

    max_date = df["Date"].max().date()
    print(f"[DATA] DB max(Date) = {max_date} | rows={len(df):,}")

    # SKIP Ï≤¥ÌÅ¨
    base = get_path("HOJ_ENGINE")
    if os.path.isfile(base):
        base = os.path.dirname(base)
    out_dir = os.path.join(base, mode.upper())
    ensure_dir(out_dir)

    tag_chk = max_date.strftime("%y%m%d")

    fname_chk = (
        f"HOJ_ENGINE_{mode.upper()}_V31"
        f"_h{horizon}"
        f"_w{input_window}"
        f"_n{n_estimators}"
        f"_{tag_chk}.pkl"
    )
    path_chk = os.path.join(out_dir, fname_chk)

    if os.path.exists(path_chk):
        print(f"\n[SKIP] ÎèôÏùº ÏÑ§Ï†ï/ÎÇ†Ïßú ÏóîÏßÑ ÏûàÏùå: {fname_chk}")
        return

    # 2) ÌîºÏ≤ò ÏÑ†ÌÉù
    features = select_feature_columns(df)
    if close_col in features:
        features = [c for c in features if c != close_col]
    print(f"[FEAT] ÌõÑÎ≥¥ ÌîºÏ≤ò Ïàò = {len(features)}")

    # 3) ÎßàÏä§ÌÅ¨
    df_m, features, max_period = apply_A_mask(df, features, input_window, close_col, horizon)
    mask_min = df_m["Date"].min().date() if len(df_m) else None
    mask_max = df_m["Date"].max().date() if len(df_m) else None
    print(f"[MASK] MaxPeriod={max_period}d | After rows={len(df_m):,} | Date: {mask_min}~{mask_max}")

    # 4) Î∂ÑÌï†
    if mode == "research":
        tr, va, valid_start, valid_end = split_train_valid(df_m, valid_days)
        tr["is_train"] = True
        va["is_train"] = False
        data = pd.concat([tr, va], ignore_index=True)
        print(f"[SPLIT] Train={len(tr):,}, Valid={len(va):,}")
    else:
        data = df_m.copy()
        data["is_train"] = True
        print(f"[SPLIT] REAL: Ï†ÑÏ≤¥ {len(data):,} ÌïôÏäµ")

    # 5) ÌïôÏäµ
    model_reg, model_cls = train_models(data, features, n_estimators=n_estimators)
    print("[TRAIN] Î™®Îç∏ ÌïôÏäµ ÏôÑÎ£å")

    # ============================================================
    # >>> ADD START ‚Äî 4-1 Ïó∞Íµ¨ Í≤∞Í≥º ÏûêÎèô ÏöîÏïΩ ÏÉùÏÑ±
    # ============================================================
    auto_summary = None
    if mode == "research":
        try:
            va_mask = (data["is_train"] == False)
            X_va = data.loc[va_mask, features]
            y_va_reg = data.loc[va_mask, "TargetRet"]
            y_va_cls = data.loc[va_mask, "TargetUp"]

            if len(X_va) > 0:
                pred_reg = model_reg.predict(X_va)
                pred_cls = model_cls.predict_proba(X_va)[:, 1]

                rmse = float(np.sqrt(np.mean((pred_reg - y_va_reg)**2)))

                from sklearn.metrics import roc_auc_score
                auc = float(roc_auc_score(y_va_cls, pred_cls))

                if auc >= 0.55:
                    stability = "ÏïàÏ†ïÏ†ÅÏûÖÎãàÎã§."
                elif auc >= 0.50:
                    stability = "Î≥¥ÌÜµ ÏàòÏ§ÄÏûÖÎãàÎã§."
                else:
                    stability = "Î∂àÏïàÏ†ïÌï©ÎãàÎã§."

                auto_summary = (
                    f"ÏµúÍ∑º Í≤ÄÏ¶ù AUC {auc:.3f}, RMSE {rmse:.4f}.\n"
                    f"Window={input_window}, Horizon={horizon} ÏÑ§Ï†ïÏùÄ {stability}"
                )
            else:
                auto_summary = "Í≤ÄÏ¶ùÎç∞Ïù¥ÌÑ∞ Î∂ÄÏ°±ÏúºÎ°ú ÏöîÏïΩ ÏÉùÏÑ± Î∂àÍ∞Ä."

        except Exception as e:
            auto_summary = f"ÏöîÏïΩ Ïò§Î•ò: {e}"

        print("\n[SUMMARY] Ïó∞Íµ¨ Í≤∞Í≥º ÏûêÎèô ÏöîÏïΩ")
        print("----------------------------------------")
        print(auto_summary)
        print("----------------------------------------")

    # ------------------------------------------------------------
    # >>> ADD START ‚Äî 4-2 Ïã§Ï†Ñ/Ïó∞Íµ¨ Í≥µÏö© Î≤†Ïù¥Ïä§ ÏÑ§Î™Ö ÏÉùÏÑ±
    # ------------------------------------------------------------
    base_summary = None
    if auto_summary:
        base_summary = (
            "‚Äª Ïù¥ ÏóîÏßÑÏùÄ ÏïÑÎûò Ïó∞Íµ¨ÏóîÏßÑÏùò Ïã§ÌóòÍ≤∞Í≥ºÎ•º Í∏∞Î∞òÏúºÎ°ú Ï†úÏûëÎêú ÏóîÏßÑÏûÖÎãàÎã§.\n"
            "   (Ïã§Ï†ÑÏóîÏßÑÏùò ÏÑ±Îä• Ï†êÏàòÍ∞Ä ÏïÑÎãàÎùº, Î≤†Ïù¥Ïä§Ïó∞Íµ¨ÏóîÏßÑÏùò Í≤ÄÏ¶ù Í≤∞Í≥ºÏûÖÎãàÎã§.)\n\n"
            + auto_summary
        )
    else:
        base_summary = "Ïó∞Íµ¨ÏóîÏßÑ ÏöîÏïΩÏ†ïÎ≥¥ ÏóÜÏùå (Í≤ÄÏ¶ùÎç∞Ïù¥ÌÑ∞ Î∂ÄÏ°± ÎòêÎäî Ïò§Î•ò)"
    # ============================================================
    # >>> ADD END
    # ============================================================

    # 6) Î©îÌÉÄ Íµ¨ÏÑ±
    meta = {
        "version": "V31",
        "data_date": str(max_date),
        "horizon": int(horizon),
        "input_window": int(input_window),
        "valid_days": int(valid_days),
        "feature_hash": _hash_list(features),
        "trained_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "close_col": close_col,
        "n_estimators": int(n_estimators),
        # >>> ADD ‚Äî base_summary Î©îÌÉÄ Ï†ÄÏû•
        "base_summary": base_summary,
    }

    payload = {
        "model_reg": model_reg,
        "model_cls": model_cls,
        "features": features,
        "meta": meta,
    }

    # 7) Ï†ÄÏû•
    save_engine(payload, mode)

    # ------------------------------------------------------------
    # >>> ADD START ‚Äî 8) HOJ_ENGINE_INFO ÏÑ§Î™ÖÌååÏùº Ï†ÄÏû•
    # ------------------------------------------------------------
    try:
        info_dir = os.path.join(
            r"F:\autostockG\MODELENGINE\HOJ_ENGINE",
            "HOJ_ENGINE_INFO"
        )
        os.makedirs(info_dir, exist_ok=True)

        engine_filename = (
            f"HOJ_ENGINE_{mode.upper()}_V31"
            f"_h{horizon}"
            f"_w{input_window}"
            f"_n{n_estimators}"
            f"_{max_date.strftime('%y%m%d')}.pkl"
        )

        info_path = os.path.join(
            info_dir,
            engine_filename.replace(".pkl", ".txt")
        )

        with open(info_path, "w", encoding="utf-8") as f:
            f.write(base_summary)

        print(f"üìÑ ÏóîÏßÑ ÏÑ§Î™ÖÌååÏùº Ï†ÄÏû• ÏôÑÎ£å: {info_path}")

    except Exception as e:
        print(f"ÏóîÏßÑ ÏÑ§Î™ÖÌååÏùº Ï†ÄÏû• Ïò§Î•ò: {e}")
    # ============================================================
    # >>> ADD END
    # ============================================================

    print("=== üèÅ Done. ===")

# ------------------------------------------------------------
# 6) CLI
# ------------------------------------------------------------
if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--mode", default="all", choices=["real","research","all"])
    ap.add_argument("--horizon", type=int, default=5)
    ap.add_argument("--input_window", type=int, default=60)
    ap.add_argument("--valid_days", type=int, default=365)
    ap.add_argument("--n_estimators", type=int, default=1000)
    ap.add_argument("--version", default="V31")
    args = ap.parse_args()

    if args.mode == "all":
        modes_to_run = ["research", "real"]
    else:
        modes_to_run = [args.mode]

    try:
        for m in modes_to_run:
            run_unified_training(
                mode=m,
                horizon=args.horizon,
                input_window=args.input_window,
                valid_days=args.valid_days,
                n_estimators=args.n_estimators,
                version=args.version,
            )
            print("-" * 60)

    except Exception as e:
        print(f"\n‚ùå [Error] {e}")
