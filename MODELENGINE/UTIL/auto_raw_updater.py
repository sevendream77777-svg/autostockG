# auto_raw_updater_v4.py (í†µí•© ìŠ¤í¬ë¦½íŠ¸)

import os
import sys
from datetime import datetime, timedelta

import pandas as pd

# V3ê°€ í•„ìš”ë¡œ í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ë“¤ì„ builder_v2ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
# V4ëŠ” V2, V3ì˜ ê¸°ëŠ¥ì„ ëª¨ë‘ ìˆ˜í–‰í•©ë‹ˆë‹¤.
try:
    from safe_raw_builder_v2 import (
        RAW_MAIN, log,
        load_all_codes, fetch_ohlcv_multi_source
    )
    from safe_raw_patch_v3 import normalize_numeric_series, fetch_single_day_multi
    
except ImportError as e:
    # ê²½ë¡œ ì„¤ì •ì„ ìœ„í•´ sys.pathë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
    current_dir = os.path.dirname(os.path.abspath(__file__))
    sys.path.append(os.path.abspath(os.path.join(current_dir, '..', 'RAW'))) 
    
    # ì¬ì‹œë„ (ìˆ˜ì • í•„ìš” ì‹œ ì´ ë¶€ë¶„ í™•ì¸)
    from safe_raw_builder_v2 import (
        RAW_MAIN, log,
        load_all_codes, fetch_ohlcv_multi_source
    )
    from safe_raw_patch_v3 import normalize_numeric_series, fetch_single_day_multi
    
    log(f"âš ï¸ ì„í¬íŠ¸ ê²½ë¡œ ë¬¸ì œë¡œ sys.pathë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤: {e}")
    
# ----------------------------------------------------------------------
# ë³´ì¡° í•¨ìˆ˜: RAW íŒŒì¼ì˜ ê°€ì¥ ìµœì‹  ë‚ ì§œë¥¼ ì°¾ëŠ” í•¨ìˆ˜
# ----------------------------------------------------------------------
def get_latest_raw_date(raw_path: str) -> Optional[datetime.date]:
    """ë©”ì¸ RAW íŒŒì¼ì—ì„œ ê°€ì¥ ìµœì‹  ë‚ ì§œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not os.path.exists(raw_path):
        return None
    
    try:
        # Date ì»¬ëŸ¼ë§Œ ì½ì–´ ë©”ëª¨ë¦¬ ì ˆì•½
        df = pd.read_parquet(raw_path, columns=["Date"])
        df["Date"] = pd.to_datetime(df["Date"])
        return df["Date"].max().date()
    except Exception as e:
        log(f"[ERROR] RAW íŒŒì¼({raw_path}) ì½ê¸° ì‹¤íŒ¨: {e}")
        return None


# ----------------------------------------------------------------------
# â­ ë©”ì¸ ìë™ ì—…ë°ì´íŠ¸ ë° ë³‘í•© í•¨ìˆ˜ (V4) â­
# ----------------------------------------------------------------------
def auto_update_raw():
    log("===== V4: ìë™ RAW ì—…ë°ì´íŠ¸ ë° ë³‘í•© ì‹œì‘ =====")
    
    if not os.path.exists(RAW_MAIN):
        log(f"[ERROR] ë©”ì¸ RAW íŒŒì¼ ì—†ìŒ ({RAW_MAIN}). ì „ì²´ êµ¬ì¶•(build_raw_all)ì´ ë¨¼ì € í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # 1. í˜„ì¬ RAWì˜ ìµœì‹  ë‚ ì§œ í™•ì¸
    latest_date = get_latest_raw_date(RAW_MAIN)
    if latest_date is None:
        log("[FATAL] RAW íŒŒì¼ì´ ë¹„ì—ˆê±°ë‚˜ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    log(f"[INFO] í˜„ì¬ RAW ìµœì‹  ë‚ ì§œ: {latest_date}")

    # 2. ìˆ˜ì§‘ ì‹œì‘ ë‚ ì§œ ì„¤ì • (ìµœì‹  ë‚ ì§œì˜ ë‹¤ìŒ ë‚ )
    start_date_to_fetch = latest_date + timedelta(days=1)
    today = datetime.now().date()
    
    # ìˆ˜ì§‘í•  ë‚ ì§œ ëª©ë¡ ìƒì„±
    fetch_dates = []
    current_date = start_date_to_fetch
    while current_date < today:
        fetch_dates.append(current_date)
        current_date += timedelta(days=1)

    if not fetch_dates:
        log("[INFO] ì—…ë°ì´íŠ¸í•  ìƒˆë¡œìš´ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—… ì¢…ë£Œ.")
        return

    log(f"[INFO] ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„: {fetch_dates[0]} ~ {fetch_dates[-1]} ({len(fetch_dates)}ì¼)")

    # 3. ë°ì´í„° ìˆ˜ì§‘ (V3 ë¡œì§) ë° ë³‘í•© ì¤€ë¹„
    codes = load_all_codes()
    all_new_data = []
    
    for date_obj in fetch_dates:
        date_str = date_obj.strftime("%Y-%m-%d")
        log(f"\n[FETCH] ë‚ ì§œ: {date_str} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        all_rows_for_day = []
        n_success = 0
        
        for code in codes:
            # fetch_single_day_multi í•¨ìˆ˜ ì‚¬ìš© (V3 ë¡œì§)
            df_day, status = fetch_single_day_multi(code, date_obj)
            
            if status == "success" and df_day is not None and not df_day.empty:
                all_rows_for_day.append(df_day)
                n_success += 1
        
        if n_success > 0 and all_rows_for_day:
            full_day_df = pd.concat(all_rows_for_day, ignore_index=True)
            log(f"[SUCCESS] {date_str}: {n_success}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ.")
            all_new_data.append(full_day_df)
        elif n_success == 0:
            log(f"[INFO] {date_str}: ê±°ë˜ì¼ ì•„ë‹˜ ë˜ëŠ” ìˆ˜ì§‘ ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœ€.")

    if not all_new_data:
        log("[INFO] ìˆ˜ì§‘ëœ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—… ì¢…ë£Œ.")
        return
        
    # 4. ê¸°ì¡´ RAW ë¡œë“œ ë° ìƒˆë¡œìš´ ë°ì´í„°ì™€ ë³‘í•© (V2 ë¡œì§ í†µí•©)
    df_main = pd.read_parquet(RAW_MAIN)
    frames = [df_main] + all_new_data
    
    merged = pd.concat(frames, ignore_index=True)
    
    # â¬‡ï¸â¬‡ï¸ 1ë‹¨ê³„ í•´ê²°: ì¤‘ë³µ ì œê±° ë¡œì§ (ì¤‘ë³µëœ ë‚ ì§œì˜ ì´ì „ ë°ì´í„°ë¥¼ ì œê±°) â¬‡ï¸â¬‡ï¸
    merged["Date"] = pd.to_datetime(merged["Date"])
    merged["Code"] = merged["Code"].astype(str).str.zfill(6)
    merged = merged.drop_duplicates(subset=["Date", "Code"], keep='last')
    
    # 5. ìµœì¢… ì •ë¦¬ ë° ì €ì¥
    merged = merged.dropna(subset=["Date", "Code"])
    merged = merged.sort_values(["Date", "Code"]).reset_index(drop=True)

    # ê¸°ì¡´ RAW ë°±ì—… (í•„ìš” ì‹œ backup_existing_raw í•¨ìˆ˜ í˜¸ì¶œ ì¶”ê°€)
    
    merged.to_parquet(RAW_MAIN)
    log(f"\nğŸ‰ [ì™„ë£Œ] RAW ìµœì¢… ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
    log(f"       ìµœì‹  ë‚ ì§œ: {merged['Date'].max().date()}, ì´ í–‰ìˆ˜: {len(merged):,}")
    log("===== ìë™ RAW ì—…ë°ì´íŠ¸ ì™„ë£Œ =====")


if __name__ == "__main__":
    auto_update_raw()