
# ============================================================
# Unified HOJ Trainer (V34 - Period Mask + Horizon Tail, wFull)
#  - Aì•ˆ: ê° í”¼ì²˜ì˜ ê¸°ê°„ë§Œí¼ ì• êµ¬ê°„ ìë™ ì œì™¸(ì˜¤ì—¼ 0%)
#  - Horizon ê¼¬ë¦¬ ì œê±°: ë§ˆì§€ë§‰ hì¼ í•™ìŠµ ì œì™¸
#  - Input Window ê¸°ë³¸ 0 (ì „ì²´ í”¼ì²˜ ì‚¬ìš©). >0ì´ë©´ ì œí•œ ê°€ëŠ¥.
#  - íŒŒì¼ ê·œì¹™/ê²½ë¡œ ìœ í‹¸ì€ ê¸°ì¡´ê³¼ ë™ì¼ ì‚¬ìš©
# ============================================================

import os
import sys
import pickle
import argparse
import re
import glob
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
import lightgbm as lgb

# ------------------------------------------------------------
# 1) ê²½ë¡œ ìœ í‹¸ ë¡œë“œ
# ------------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)   # MODELENGINE
root_dir = os.path.dirname(parent_dir)      # Root
sys.path.append(root_dir)

try:
    from MODELENGINE.UTIL.config_paths import get_path
    from MODELENGINE.UTIL.version_utils import find_latest_file
except ImportError:
    sys.path.append(parent_dir)
    from UTIL.config_paths import get_path
    from UTIL.version_utils import find_latest_file

# ------------------------------------------------------------
# 2) í—¬í¼ë“¤
# ------------------------------------------------------------
def get_db_path(version: str = "V31") -> str:
    """ìµœì‹  ë‚ ì§œ íƒœê·¸ê°€ ë¶™ì€ HOJ_DB_{version}_YYMMDD[_n].parquet ìš°ì„  ì‚¬ìš©"""
    base_dir = get_path("HOJ_DB")
    if "REAL" in base_dir or "RESEARCH" in base_dir:
        base_dir = os.path.dirname(base_dir)
    latest_db = find_latest_file(base_dir, f"HOJ_DB_{version}")
    if latest_db:
        return latest_db
    return os.path.join(base_dir, f"HOJ_DB_{version}.parquet")

def ensure_datetime(df: pd.DataFrame, col: str = "Date") -> pd.DataFrame:
    if not np.issubdtype(df[col].dtype, np.datetime64):
        df[col] = pd.to_datetime(df[col], errors="coerce")
    return df

def build_dynamic_target(df: pd.DataFrame, horizon: int) -> pd.DataFrame:
    """ìš”ì²­í•œ Horizon(ì¼) ì •ë‹µ(Return_{h}d, Label_{h}d) ì—†ìœ¼ë©´ ìƒì„±"""
    ret_col = f"Return_{horizon}d"
    lab_col = f"Label_{horizon}d"
    if ret_col in df.columns and lab_col in df.columns:
        return df
    if "Close" not in df.columns:
        raise KeyError("DBì— 'Close'ê°€ ì—†ì–´ íƒ€ê²Ÿì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    df = df.sort_values(["Code", "Date"]).copy()
    df[ret_col] = df.groupby("Code")["Close"].shift(-horizon) / df["Close"] - 1.0
    df[lab_col] = (df[ret_col] > 0).astype(int)
    return df

def get_save_filename(mode: str, version: str, data_date: str, horizon: int,
                      input_window: int, n_estimators: int, train_date: str) -> str:
    iw_tag = f"w{input_window}" if input_window > 0 else "wFull"
    return (
        f"HOJ_ENGINE_{mode.upper()}_{version}_"
        f"d{data_date}_"
        f"h{horizon}_"
        f"{iw_tag}_"
        f"n{n_estimators}_"
        f"t{train_date}.pkl"
    )

def extract_max_period_from_features(columns) -> int:
    """ì»¬ëŸ¼ëª… ë‚´ ìˆ«ìë“¤ì—ì„œ ê°€ì¥ í° ê¸°ê°„ì„ ì¶”ì¶œ (ì—†ìœ¼ë©´ 0)"""
    max_p = 0
    for col in columns:
        nums = re.findall(r"\d+", str(col))
        if nums:
            try:
                period = int(nums[-1])
                if period > max_p:
                    max_p = period
            except:
                pass
    return max_p

# ------------------------------------------------------------
# 3) ë©”ì¸ ë¡œì§
# ------------------------------------------------------------
def run_unified_training(
    mode: str = "research",
    horizon: int = 5,
    input_window: int = 0,        # ê¸°ë³¸: ì „ì²´ í”¼ì²˜ ì‚¬ìš©
    valid_days: int = 365,
    n_estimators: int = 1000,
    version: str = "V31",
) -> None:
    mode = mode.lower()
    print("\\n=== [HOJ Engine Factory V34] ì‹œì‘ =========================")
    print(f"[Config] Mode={mode.upper()} | Horizon={horizon}d | InputWindow={input_window or 'Full'} | Valid={valid_days}d")

    # [A] DB ë¡œë“œ
    db_path = get_db_path(version)
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
    print(f"[Load] DB: {os.path.basename(db_path)}")
    df = pd.read_parquet(db_path)
    df = ensure_datetime(df)
    df = df.sort_values(['Date','Code']).reset_index(drop=True)

    min_date = df['Date'].min().date()
    max_date_obj = df['Date'].max()
    max_date = max_date_obj.date()
    data_date_tag = max_date.strftime("%y%m%d")
    print(f"[Info] ë°ì´í„° ê¸°ê°„: {min_date} ~ {max_date} | Rows={len(df):,}")

    # [B] íƒ€ê²Ÿ ì¤€ë¹„
    df = build_dynamic_target(df, horizon)
    ret_col = f"Return_{horizon}d"
    lab_col = f"Label_{horizon}d"

    # [C] í”¼ì²˜ ì„ ì •
    exclude_cols = [
        "Code","Date","Name","Market",
        "Open","High","Low","Close","Volume","Amount","Marcap",
        "KOSPI_ì¢…ê°€","KOSPI_ìˆ˜ìµë¥ ",
        ret_col, lab_col, f"Expected_{ret_col}",
    ]
    exclude_cols += [c for c in df.columns if c.startswith("Return_") or c.startswith("Label_")]
    feature_cols = df.columns.difference(exclude_cols).tolist()
    feature_cols = df[feature_cols].select_dtypes(include=['number','bool']).columns.tolist()

    # [C-1] Input Windowê°€ >0 ì´ë©´ ê¸´ ì§€í‘œ ì œì™¸(ì˜µì…˜)
    if input_window and input_window > 0:
        print(f"[Filter] InputWindow={input_window} ì ìš©(ê¸°ê°„ ì´ˆê³¼ ì§€í‘œ ì œì™¸)")
        keep, drop = [], []
        for col in feature_cols:
            nums = re.findall(r"\\d+", col)
            if nums and int(nums[-1]) > input_window:
                drop.append(col)
            else:
                keep.append(col)
        feature_cols = keep
        if drop:
            print(f"        ì œì™¸ {len(drop)}: {drop}")

    if not feature_cols:
        raise ValueError("í•™ìŠµí•  í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤. Input Window ì„¤ì • ë˜ëŠ” DB ì»¬ëŸ¼ í™•ì¸.")

    # [D] Aì•ˆ: ê¸°ê°„ë§Œí¼ ì• êµ¬ê°„ ì œì™¸ + Horizon ê¼¬ë¦¬ ì œê±°
    max_period = extract_max_period_from_features(feature_cols)
    print(f"[Mask] MaxPeriod={max_period}d | HorizonTail={horizon}d ì œê±°")

    def _apply_masks(g: pd.DataFrame) -> pd.DataFrame:
        g = g.sort_values("Date")
        # ì•: ìµœëŒ€ ê¸°ê°„ë§Œí¼ ì œì™¸
        if max_period > 0:
            g = g.iloc[max_period:]
        # ë’¤: horizon ê¼¬ë¦¬ ì œì™¸
        if horizon > 0 and len(g) > horizon:
            g = g.iloc[:-horizon]
        return g

    df_masked = (
        df.groupby("Code", group_keys=False)
          .apply(_apply_masks)
          .reset_index(drop=True)
    )
    # ì„ íƒëœ í”¼ì²˜ + íƒ€ê²Ÿ ê²°ì¸¡ ì œê±°
    mask = df_masked[feature_cols].notnull().all(axis=1) & df_masked[ret_col].notnull()
    df_train = df_masked[mask].copy()
    print(f"[Data] ë§ˆìŠ¤í¬/NaN ì œê±° í›„ í•™ìŠµ ë°ì´í„°: {len(df_train):,} rows (From {df_train['Date'].min().date()})")

    # [E] Train/Valid Split & í•™ìŠµ
    params_common = {
        "n_estimators": n_estimators,
        "learning_rate": 0.03,
        "num_leaves": 63,
        "feature_fraction": 0.9,
        "bagging_fraction": 0.9,
        "bagging_freq": 3,
        "n_jobs": -1,
        "verbose": -1,
        "random_state": 42,
    }

    metrics = {}
    if mode == "research":
        split_date = max_date_obj - timedelta(days=valid_days)
        print(f"[Split] Research ë¶„í• : split={split_date.date()}")
        mask_tr = df_train["Date"] < split_date
        mask_va = df_train["Date"] >= split_date

        X_tr = df_train.loc[mask_tr, feature_cols]
        y_tr_reg = df_train.loc[mask_tr, ret_col]
        y_tr_cls = df_train.loc[mask_tr, lab_col]

        X_va = df_train.loc[mask_va, feature_cols]
        y_va_reg = df_train.loc[mask_va, ret_col]
        y_va_cls = df_train.loc[mask_va, lab_col]

        print(f"[Size] Train={len(X_tr):,} | Valid={len(X_va):,}")
        print("[Train] íšŒê·€/ë¶„ë¥˜ ë™ì‹œ í•™ìŠµ(ES=100)...")
        model_reg = lgb.LGBMRegressor(objective="regression", metric="rmse", **params_common)
        model_reg.fit(X_tr, y_tr_reg, eval_set=[(X_va, y_va_reg)], callbacks=[lgb.early_stopping(100, verbose=False)])

        model_cls = lgb.LGBMClassifier(objective="binary", metric="binary_logloss", **params_common)
        model_cls.fit(X_tr, y_tr_cls, eval_set=[(X_va, y_va_cls)], callbacks=[lgb.early_stopping(100, verbose=False)])

        rmse = float(np.sqrt(np.mean((model_reg.predict(X_va) - y_va_reg) ** 2)))
        acc  = float(np.mean(model_cls.predict(X_va) == y_va_cls))
        print(f"[Eval] RMSE={rmse:.5f} | ACC={acc:.2%}")
        metrics = {"rmse": rmse, "acc": acc}
    else:
        print("[Train] Real ëª¨ë“œ: ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ")
        X_tr = df_train[feature_cols]
        y_tr_reg = df_train[ret_col]
        y_tr_cls = df_train[lab_col]

        model_reg = lgb.LGBMRegressor(objective="regression", metric="rmse", **params_common)
        model_reg.fit(X_tr, y_tr_reg)

        model_cls = lgb.LGBMClassifier(objective="binary", metric="binary_logloss", **params_common)
        model_cls.fit(X_tr, y_tr_cls)

        metrics = {"note": "Real mode full train"}

    # [F] ì €ì¥
    save_dir = get_path("HOJ_ENGINE", mode.upper())
    os.makedirs(save_dir, exist_ok=True)
    train_date_tag = datetime.now().strftime("%y%m%d")
    save_name = get_save_filename(mode, version, data_date_tag, horizon, input_window, n_estimators, train_date_tag)
    save_path = os.path.join(save_dir, save_name)

    payload = {
        "model_reg": model_reg,
        "model_cls": model_cls,
        "features": feature_cols,
        "meta": {
            "mode": mode,
            "version": version,
            "horizon": horizon,
            "input_window": input_window,
            "n_estimators": n_estimators,
            "data_date": str(max_date),
            "train_date": str(datetime.now().date()),
            "metrics": metrics,
        },
    }
    with open(save_path, "wb") as f:
        pickle.dump(payload, f)

    print(f"[Save] ì—”ì§„ ì €ì¥ ì™„ë£Œ: {os.path.basename(save_path)}")
    print("=== [HOJ Engine Factory V34] ì™„ë£Œ =========================\\n")


# ------------------------------------------------------------
# 4) CLI
# ------------------------------------------------------------
if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--mode", default="all", help="all | research | real (ê¸°ë³¸ all: ë‘˜ ë‹¤ ìˆœì°¨ ì‹¤í–‰)")
    p.add_argument("--horizon", type=int, default=5, help="ì˜ˆì¸¡í•  ë¯¸ë˜ ì¼ìˆ˜ (ì˜ˆ: 5)")
    p.add_argument("--input_window", type=int, default=0, help="0ì´ë©´ ì „ì²´ í”¼ì²˜, >0ì´ë©´ ê¸°ê°„ ì œí•œ")
    p.add_argument("--valid_days", type=int, default=365)
    p.add_argument("--n_estimators", type=int, default=1000)
    p.add_argument("--version", type=str, default="V31")
    args = p.parse_args()

    modes = []
    if args.mode.lower() in ("all","research"):
        modes.append("research")
    if args.mode.lower() in ("all","real"):
        modes.append("real")

    for m in modes:
        print(f"\\nğŸš€ [Pipeline] {m.upper()} ì—”ì§„ í•™ìŠµ ì‹œì‘")
        run_unified_training(
            mode=m,
            horizon=args.horizon,
            input_window=args.input_window,
            valid_days=args.valid_days,
            n_estimators=args.n_estimators,
            version=args.version,
        )
