# explore_RESEARCH_DB_V31.py
# --- V31 ì—°êµ¬ DB êµ¬ì¡°/ìƒíƒœ ì ê²€ìš© ìŠ¤í¬ë¦½íŠ¸ ---

import pandas as pd
import numpy as np
import os

# ğŸ”§ ì—¬ê¸°ë§Œ ì‹¤ì œ íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•´ì„œ ì“°ì„¸ìš”
RESEARCH_DB_FILE = r"F:\autostockG\MODELENGINE\HOJ_DB\RESEARCH\HOJ_DB_RESEARCH_V31.parquet"  # ì˜ˆì‹œ

def main():
    if not os.path.exists(RESEARCH_DB_FILE):
        print(f"âŒ ì˜¤ë¥˜: ì—°êµ¬ DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n -> ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {RESEARCH_DB_FILE}")
        return

    print(f"[1] ì—°êµ¬ DB(V31) ë¡œë“œ ì¤‘...\n    íŒŒì¼: {RESEARCH_DB_FILE}")
    df = pd.read_parquet(RESEARCH_DB_FILE)
    print(f"âœ… ë¡œë“œ ì™„ë£Œ: {df.shape[0]:,} í–‰, {df.shape[1]:,} ì»¬ëŸ¼\n")

    # --- 1. ê¸°ë³¸ ë©”íƒ€ ì •ë³´ ---
    print("[2] ê¸°ë³¸ ì •ë³´")
    print("- ìƒìœ„ 5í–‰ ë¯¸ë¦¬ë³´ê¸°:")
    print(df.head(5))
    print("\n- ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸:")
    print(list(df.columns))
    print()

    # --- 2. í•µì‹¬ í‚¤ ì»¬ëŸ¼ ìë™ ê°ì§€ ---
    print("[3] í•µì‹¬ ì»¬ëŸ¼ ì²´í¬ (Code / ì¢…ëª© / ë‚ ì§œ / ìˆ˜ìµë¥  / ë¼ë²¨ ë“±)")

    candidate_code_cols = ["Code", "code", "ì¢…ëª©ì½”ë“œ", "ticker"]
    candidate_date_cols = ["Date", "date", "ë‚ ì§œ", "dt"]
    candidate_close_cols = ["Close", "close", "ì¢…ê°€"]
    candidate_label_cols = ["Label_5d", "label_5d", "Label", "label"]
    candidate_target_cols = [
        "Expected_Return_5d", "Return_5d",
        "expected_return_5d", "return_5d"
    ]

    def find_existing(candidates):
        return [c for c in candidates if c in df.columns]

    code_cols = find_existing(candidate_code_cols)
    date_cols = find_existing(candidate_date_cols)
    close_cols = find_existing(candidate_close_cols)
    label_cols = find_existing(candidate_label_cols)
    target_cols = find_existing(candidate_target_cols)

    print(f" - ì¢…ëª© ì½”ë“œ í›„ë³´: {code_cols}")
    print(f" - ë‚ ì§œ ì»¬ëŸ¼ í›„ë³´: {date_cols}")
    print(f" - ì¢…ê°€ ì»¬ëŸ¼ í›„ë³´: {close_cols}")
    print(f" - ë¼ë²¨ ì»¬ëŸ¼ í›„ë³´: {label_cols}")
    print(f" - íƒ€ê¹ƒ(ìˆ˜ìµë¥ ) ì»¬ëŸ¼ í›„ë³´: {target_cols}")
    print()

    # --- 3. ë‚ ì§œ/ì¢…ëª© ë²”ìœ„ ìš”ì•½ ---
    print("[4] ë‚ ì§œ / ì¢…ëª© ë²”ìœ„ ìš”ì•½")
    code_col = code_cols[0] if code_cols else None
    date_col = date_cols[0] if date_cols else None

    if date_col is not None:
        try:
            df[date_col] = pd.to_datetime(df[date_col])
        except Exception:
            pass

        print(f" - ë‚ ì§œ ìµœì†Œê°’: {df[date_col].min()}")
        print(f" - ë‚ ì§œ ìµœëŒ€ê°’: {df[date_col].max()}")
    else:
        print(" - ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    if code_col is not None:
        print(f" - ì¢…ëª© ê°œìˆ˜: {df[code_col].nunique():,} ê°œ")
        print(f" - ì˜ˆì‹œ ì¢…ëª© 5ê°œ: {df[code_col].dropna().unique()[:5]}")
    else:
        print(" - ì¢…ëª© ì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    print()

    # --- 4. ê²°ì¸¡ì¹˜(NaN) ìš”ì•½ ---
    print("[5] ê²°ì¸¡ì¹˜ ìš”ì•½ (ìƒìœ„ 30ì»¬ëŸ¼)")
    null_sum = df.isna().sum().sort_values(ascending=False)
    null_ratio = (null_sum / len(df)).sort_values(ascending=False)

    null_summary = pd.DataFrame({
        "null_count": null_sum,
        "null_ratio": null_ratio
    })
    print(null_summary.head(30))
    print()

    # --- 5. ë¼ë²¨/íƒ€ê¹ƒ ë¶„í¬ ì²´í¬ ---
    print("[6] ë¼ë²¨/íƒ€ê¹ƒ ë¶„í¬")
    if label_cols:
        lbl = label_cols[0]
        print(f" - ë¼ë²¨ ì»¬ëŸ¼: {lbl}")
        print(df[lbl].value_counts(dropna=False))
        print()
    else:
        print(" - ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n")

    if target_cols:
        tgt = target_cols[0]
        print(f" - íƒ€ê¹ƒ ì»¬ëŸ¼: {tgt}")
        print(df[tgt].describe(percentiles=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]))
        print()
    else:
        print(" - íƒ€ê¹ƒ(ìˆ˜ìµë¥ ) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n")

    # --- 6. í”¼ì²˜ ê°œìˆ˜/ëª©ë¡ ---
    print("[7] í”¼ì²˜ ì»¬ëŸ¼ ê°œìˆ˜ ë° ì˜ˆì‹œ")

    base_cols = set(code_cols + date_cols + close_cols + label_cols + target_cols)
    feature_cols = [c for c in df.columns if c not in base_cols]

    print(f" - ì „ì²´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
    print(f" - í”¼ì²˜(íŠ¹ì§•) ì»¬ëŸ¼ ìˆ˜: {len(feature_cols)}")
    print(f" - í”¼ì²˜ ì»¬ëŸ¼ ì˜ˆì‹œ(ìµœëŒ€ 40ê°œ):")
    print(feature_cols[:40])
    print()

    # --- 7. ìƒ˜í”Œ ì¢…ëª© í•œ ê°œ íƒ€ì„ë¼ì¸ ë³´ê¸° ---
    print("[8] ìƒ˜í”Œ ì¢…ëª© íƒ€ì„ë¼ì¸ (ìƒìœ„ 1ê°œ ì¢…ëª©)")
    if code_col is not None and date_col is not None:
        sample_code = df[code_col].dropna().unique()[0]
        print(f" - ìƒ˜í”Œ ì¢…ëª©: {sample_code}")
        sub = df[df[code_col] == sample_code].sort_values(date_col).head(20)
        print(sub[[col for col in [date_col, code_col] + target_cols + label_cols if col in sub.columns]])
    else:
        print(" - ì¢…ëª©/ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ì–´ ìƒ˜í”Œ íƒ€ì„ë¼ì¸ì„ ì¶œë ¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # --- 8. ê²°ê³¼ ìš”ì•½ CSVë¡œ ì €ì¥ (ì˜µì…˜) ---
    print("\n[9] ìš”ì•½ ë¦¬í¬íŠ¸ CSV ì €ì¥")
    out_dir = os.path.dirname(RESEARCH_DB_FILE)
    null_summary_path = os.path.join(out_dir, "V31_null_summary.csv")
    cols_info_path = os.path.join(out_dir, "V31_columns_list.csv")

    null_summary.to_csv(null_summary_path, encoding="utf-8-sig")
    pd.DataFrame({"columns": df.columns}).to_csv(cols_info_path, index=False, encoding="utf-8-sig")

    print(f" - ê²°ì¸¡ì¹˜ ìš”ì•½: {null_summary_path}")
    print(f" - ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸: {cols_info_path}")
    print("\nâœ… V31 ì—°êµ¬ DB íƒìƒ‰ 1ì°¨ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ.")

if __name__ == "__main__":
    main()
